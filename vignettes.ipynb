{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from data_utils import DataSeqLoader\n",
    "# from nn_many2one import *\n",
    "from nn_models import EmbeddingLSTMModel, TimeDistributedOneHotEncoding\n",
    "from data_gen import data_gen\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.12.0'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate a simulated dataset using `data_gen`.\n",
    "\n",
    "Here we are assuming that there are 1000 patients, and 20 continuous longitudinal measures (including missingness), and a patient can have up to 30 observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = data_gen(n=1000, p=20, max_t=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe the number of case and control groups from the simulated data as follows.\n",
    "\n",
    "`0` means control; `1` means case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    904\n",
       "1     96\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.groupby('id').last()['y'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot the distribution of the number of observations of the patients, which should approximate a uniform distribution by construction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Density'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAD4CAYAAAD7CAEUAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAu9klEQVR4nO3deXxc1ZXo+9/SLEuyNcuSLFuSkY1lBmGEMYEmjB1DAENySSAECEnaoYPzSDq3b5P0RPqlX0i6k7zmhoZAQgOZ3ORBGofrhDYOQ8JoG8+zLHmQJWuwbI3WWOv9UaegkDVUyXV0qqT1/XyKqnPOPlVrY6mWzt777C2qijHGGBOqOK8DMMYYE1sscRhjjAmLJQ5jjDFhscRhjDEmLJY4jDHGhCXB6wAmQ25urpaWlnodhjHGxJRNmza1qmre8P3TInGUlpayceNGr8MwxpiYIiKHRtpvTVXGGGPCYonDGGNMWCxxGGOMCYslDmOMMWGxxGGMMSYsljiMMcaExRKHMcaYsEyL+ziMMdA3OMSGuhPsOdZB78AQc7JmcFlFLrnpyV6HZmKMJQ5jprjegSF+8sdannzjIG3d/R86Fidww3lF/PXHFlKSPcOjCE2sscRhzBS242g7X/3PLdQ0d3HV2fnccfFcLpyXRUpiPDXNXazZ2sAzbx1k/e4m/vmWc7n5gmKvQzYxwBKHMVPUSzuPcf/qzWTNSOKpey7iioX5Hzp+TvEszimexd0fKeVrq7fw1f/cwuG2Hr5y1VmIiEdRm1jgaue4iCwXkb0iUiMiD4xwXETkYef4NhFZ4uxPEZF3RWSriOwUkW8FnfOgiBwVkS3O43o362BMLPrlO4e59+ebWFQ4kzWrLjstaQQrzkzlF39xMZ9cMocfrNvHQ7/fM4mRmljk2hWHiMQDjwDXAvXABhFZo6q7gopdB1Q4j4uBR53nPuAqVe0SkUTgTyLyO1V92znvh6r6r27Fbkwse3bDEb75m+1cdXY+/37HElIS48c9JzE+jn+99TxSk+L48Wu1ZKYm8ZdXzJ+EaE0scrOpailQo6q1ACKyGlgBBCeOFcAzqqrA2yKSKSKFqtoIdDllEp2HuhirMVPCmq0N/M3z27h8QV7ISSNARPinm86hs3eQ7/5+D/kZyXzywjkuRmtilZtNVcXAkaDtemdfSGVEJF5EtgDNwDpVfSeo3CqnaetJEcka6cNFZKWIbBSRjS0tLWdYFWOi37t1bfzPZ7dyUWk2j995YVhJIyAuTvjXW8/n0rNy+Mbz29l4sM2FSE2sczNxjNS7NvyqYdQyqjqkqlXAHGCpiJzjHH8UmA9UAY3A90f6cFV9XFWrVbU6L++0dUiMmVLqWrtZ+bONzMlKnXDSCEiMj+ORzyyhOCuVL/1sE0faeiIYqZkK3Ewc9UBJ0PYcoCHcMqp6EngVWO5sNzlJxQc8gb9JzJhp60R3P59/agNxIvzHPReROSPpjN8zc0YSP7m7moEhH198eiNdfYMRiNRMFW4mjg1AhYiUiUgScBuwZliZNcBdzuiqZUC7qjaKSJ6IZAKISCpwDbDH2S4MOv8WYIeLdTAmqvUNDvGln23i6IlTPH7nhczLSYvYe8/PS+eRO5ZQ09LF/b/azJDPuhmNn2uJQ1UHgVXAS8Bu4FlV3Ski94rIvU6xtUAtUIP/6uHLzv5C4BUR2YY/Aa1T1RedY98Tke3OsSuBr7lVB2OimarywHPbefdgG/9y63lUl2ZH/DP+rCKPB2+sZP2eZr712534x7GY6c7VGwBVdS3+5BC877Gg1wrcN8J524ALRnnPOyMcpjEx6eH1Nfxm81G+fu0CVlS5d8f3nZeUcuTEKR5/vZbizFS+9FEbpjvd2Z3jxsSgF7Yc5Ycv7+MTS4pZddVZrn/eA8vPpuHkKb7zuz1kpyVxa3XJ+CeZKcsShzExZuPBNv7619tYWpbNdz5x7qRMDxIXJ3z/U+fTfmqA//XcNnyqfPqiua5/rolOth6HMSHo6R+kd2DI8zb+Q8e7WfmzTRRnpfLjz15IcsLEh92GKzkhnifuqubyijz+5rntPLx+Pz7rMJ+W7IrDmBEca+/l+c31vL6vhV0NHXT0+oejzkxJ4Lw5mVxbWcCN5xeRnXbmQ19DFRh261Plyc9dRNYkfnZASmI8j991Id94fjs/WLeP7Ufb+c4nzrU1PaYZ8fovqMlQXV2tGzdu9DoMEwMOH+/huy/t4fc7jjHkUyoLZ3LhvCwKM1NQhaMnT7Hp4An2NnWSkhjH3ZeU8uUrzmLWjERX4+rqG+SOn7zD7sYOfvb5pVxcnuPq541HVfmPNw7ynd/tZkZSAn/9sYV8qrqEpARrxJhKRGSTqlaftt8ShzH++yF+/Fotj7xSQ0Kc8Nll87jj4nnMzRl5caPdjR088Xot/7XlKNlpyTx4UyUfP7fQlf6GvsEhPv/UBt6ubePRO5bw54tnR/wzJqqmuYtv/mY779a1UTgrhS/+WTmfqp5DRoq7idRMDkscljjMKF7f18I/rtlJXWs3Hz+3kL+7YRGFs1JDOndnQzvfeH472+rbueWCYr598zmkJUeuBbh/0MeqX77Hf+9q4vu3nh+Vkw6qKq/vb+WRP9Tw7sE20pMT+FR1CZ/7SOmoidfEBkscljjMMI3tp/j2i7v5P9sbKctN41s3LebyBeHPazY45OORVw7wb+v3UZqTxo8+s4TKoplnHF/vwBB/+fNNvLK3hQdvrORzl5ad8Xu6beuRk/zHG3W8uK2RIVWuXVTA/3V1BecUz/I6NDMBljgsccSUpo5ette3c2pgiIKZKSwsyIhYP0L/oI+n3zzID1/ex5BPWXXlWaz8aPkZj1B668Bx7l+9mZOnBvj7jy/is8vmTbjpqv3UAH/58028eeA4/3zLOdxx8bwzim2yNXX08rO3DvGLdw7R0TvIX127gC9fMd9WFowxljgsccSEnQ3tfPvF3bxVe/xD+0XgwrlZfGzxbD5+XiFFmaE1JQ33yp5m/u8Xd1Hb2s1VZ+fzrZsWU5IdueaU1q4+vv7sVl7b18LHFhfw3U+eF/akg3Wt3Xzh6Q0caevhu588j08sib7mqVC19wzwdy/s4LdbG7h9aQn/fPO5xMVZ8ogVljgscUS9F7Yc5evPbiVzRhL3XFrKsvIcMlISOHryFJsPn+TlXU3sauwAYGlpNjdWFXH9ObPJGWcoqM+nvLa/hUdfPcC7dW2U56bx9zdUcuXZoy+neiZ8PuXJN+r47u/3kJuezD/fcg5XnV0w7nmqyrMbj/BPv91FUkIcj372QpZ5PHoqElSVf3lpL//+6gFWXXkW//NjC70OyYTIEocljqi2dnsjq375HheVZvPjOy8c9a/0g63d/HZrA2u2NrC/uYv4OOHSs3L588oCFhVmUDgrlcT4ONpP9VPT3MW7dSf43Y5GGtt7KZyVwpcuL+czF8+blGGj2+vb+dqzW6hp7uLKhXmsuqqCC+edvu6YqrLh4Am+/997eaeujUvKc/iXW89jTtbU6VhWVb7x/HZWbzjCE3dVc23l+InUeM8ShyWOqHWwtZsb/vefqChI55dfXEZq0vh9DarKnmOdrNnawG+3NlB/4tSI5ZLi47h8QS43VRWzfPHsSb/PINCf8vAf9tPZO0hFfjqXVeQyL3sGChw63sNr+1qoa+0mNz2Zr15TwWeWzp2SzTn9gz5WPPIGx7v6WPdXH2VWqg3ZjXaWOCxxRCVV5VM/fot9TV2svf/PKJ5A34WqUn/iFPuaOmnp7KN/yMes1ERKsmdQWTjzjFbDi5TuvkGef6+el3Y2seFgG32DPgBSE+O5YG4mN55fxIqqImYkTe3JHHYcbWfFI29w57J5PHjTYq/DMeMYLXFM7Z9SE/XWbj/GhoMn+M4nzp1Q0gAQEUqyZ0S0kzvS0pITuPOSUu68pBSfTznR04+IMCs1kfgpeHUxmnOKZ3HrhXP45TuH+YvLyyf8b268ZfMDGM8MDvn47u/3cPbsDD41jabpjosTctKTyU5LmlZJI+ArV1cA8KM/7Pc4EjNRljiMZ17a2cThth6+es2CafkFOl0VZ6byyQvn8Px7RznR3e91OGYCLHEYT6gqT/yxlnk5M2yEzTR090fm0Tfo49ebjngdipkAVxOHiCwXkb0iUiMiD4xwXETkYef4NhFZ4uxPEZF3RWSriOwUkW8FnZMtIutEZL/zfPr4RhP1th9tZ8uRk3z+0jK72piGzp49k6Wl2fz87cOer3Fiwuda4hCReOAR4DqgErhdRCqHFbsOqHAeK4FHnf19wFWqej5QBSwXkWXOsQeA9apaAax3tk2Mef69oyQlxHHzBe6tlW2i26cvKuFwWw/vHT7pdSgmTG5ecSwFalS1VlX7gdXAimFlVgDPqN/bQKaIFDrbXU6ZROehQec87bx+GrjZxToYF/QP+liztYFrKwtsLP809ueLC0hOiGPNlqNeh2LC5GbiKAaCGzDrnX0hlRGReBHZAjQD61T1HadMgao2AjjP7swbYVzz+r4W2rr7+eQSu9qYzjJSErl6UT7/Z3sjg0M+r8MxYXAzcYzUcD28MXPUMqo6pKpVwBxgqYicE9aHi6wUkY0isrGlpSWcU43L/nvXMTJSErjsrPCnMDdTy43nFdHa1c/GQye8DsWEwc3EUQ8ED86fAzSEW0ZVTwKvAsudXU0iUgjgPDeP9OGq+riqVqtqdV6efUFFiyGfsn53M1cszLdlRg1/tiCPxHjhlT0j/hqbKOXmb+4GoEJEykQkCbgNWDOszBrgLmd01TKgXVUbRSRPRDIBRCQVuAbYE3TO3c7ru4EXXKyDibAtR05yvLufaxZZC6OB9OQElpXnsN4SR0xxLXGo6iCwCngJ2A08q6o7ReReEbnXKbYWqAVqgCeALzv7C4FXRGQb/gS0TlVfdI49BFwrIvuBa51tEyNe3t1EQpxwxQJLHMbvyoX51DR3ceh4t9ehmBC5OleVqq7FnxyC9z0W9FqB+0Y4bxtwwSjveRy4OrKRmsnyh93NXFSaHbHV/Ezsu+rsfP7pxV28tq+Fuy5J8zocEwJrZDaTprmzl71NnXx0ofU5mQ/My5lB0awU3h626qOJXpY4zKR5u7YNgEumwKp2JnJEhGXzc3i7tg2fz+4ijwWWOMykeetAKxnJCSwumul1KCbKXFKeQ1t3P/ubu8YvbDxnicNMmrcOHGdpWTYJ8fZjZz4ssLa6NVfFBvsNNpOisf0UB4/3cMl8a6YypyvJnsGcrFTeOmCJIxZY4jCTIvCXpCUOM5pl5Tm8e7DNZsuNAZY4zKTYdOgE6ckJnD3b+jfMyJbMzaKtu5/DbT1eh2LGYYnDTIrNh09SVZJpa2+YUVWVZAL+2QVMdLPEYVzX0z/InmOdXDA30+tQTBRbUJBOamI8m219jqhnicO4blt9O0M+tcRhxpQQH8d5c2ax2a44op4lDuO6wF+QVSW2yq8ZW9XcTHY1tNM7MOR1KGYMljiM6zYfPkFZbhrZaUleh2Ki3AUlWQwMKbsaO7wOxYzBEodx3eYjJ9/v+DRmLIHmzC3WzxHVLHEYVzV39NLS2ce5xbO8DsXEgPyMZHLTk+yKI8pZ4jCu2tHQDsA5ljhMCESEyqJZ7GqwxBHNLHEYV+086v8CWFSY4XEkJlZUFs5kf3Mn/YM+r0Mxo7DEYVy1s6GD0pwZZKTYwk0mNIuLZjIwpOxv7vQ6FDMKSxzGVTsb21lcZM1UJnSVzrT7O625KmpZ4jCuae8Z4EjbKRYX2/xUJnSlOWmkJsZbP0cUczVxiMhyEdkrIjUi8sAIx0VEHnaObxORJc7+EhF5RUR2i8hOEbk/6JwHReSoiGxxHte7WQczcTsb/R3jdsVhwhEfJywqzLCRVVHMtcQhIvHAI8B1QCVwu4hUDit2HVDhPFYCjzr7B4Gvq+oiYBlw37Bzf6iqVc5jrVt1MGcm8BejrfhnwlVZNJPdDR22lGyUcvOKYylQo6q1qtoPrAZWDCuzAnhG/d4GMkWkUFUbVfU9AFXtBHYDxS7Galyws6GDgpnJ5KYnex2KiTGLi2bR2TfIkRM2xXo0cjNxFANHgrbrOf3Lf9wyIlIKXAC8E7R7ldO09aSIjDgBkoisFJGNIrKxpaVlglUwZ2J3YweVhXa1YcK3yPm52XPMRlZFIzcTx0gLLwy/7hyzjIikA88BX1XVQIPno8B8oApoBL4/0oer6uOqWq2q1Xl5eWGGbs7UwJCPAy1dLLSFm8wEVOSnA7C/yRJHNHIzcdQDJUHbc4CGUMuISCL+pPELVX0+UEBVm1R1SFV9wBP4m8RMlDnY2s3AkLJwdrrXoZgYlJacQHFmKvuaurwOxYzAzcSxAagQkTIRSQJuA9YMK7MGuMsZXbUMaFfVRhER4KfAblX9QfAJIlIYtHkLsMO9KpiJCvzCV+TbHeNmYhYUpLPPrjiiUoJbb6yqgyKyCngJiAeeVNWdInKvc/wxYC1wPVAD9AD3OKdfCtwJbBeRLc6+bzojqL4nIlX4m7QOAl9yqw5m4vY2dRIncFa+XXGYiVlQkMEbNccZHPKREG+3nEUT1xIHgPNFv3bYvseCXitw3wjn/YmR+z9Q1TsjHKZxwb5jnZTmpJGSGO91KCZGVRRk0D/k41BbD/Pz7A+QaGJp3LhiX1MnCwqsmcpM3IIC6yCPVpY4TMT1Dgxx8Hg3C2Zb4jATF2jmtA7y6GOJw0TcgZYufAoL7YrDnIEZSQmUZKdaB3kUssRhIi7wix5oajBmohbkZ7DfrjiijiUOE3F7j3WRGC+U5qZ5HYqJcRUFGdS2djEwZIs6RRNLHCbi9jV1Mj8vnUQbQmnO0IKCdAaGlEPHu70OxQSx32wTcfuaOqmw/g0TAYGRedZBHl0scZiIOtU/xNGTpzjLxt2bCCjP8zd3Hmi2xBFNLHGYiKpr7UYV5udb/4Y5czOSEiialUJtqzVVRRNLHCaialv9fxmW59oVh4mM8rx0DrTYFUc0scRhIupAczciUGYjqkyEzM9Lo7alG/8MRSYaWOIwEVXb2kXRrFRSk2yOKhMZ5XnpdPUN0tLZ53UoxmGJw0TUgZYu5tuMuCaC3u8gb7F+jmhhicNEjKpS29JNuTVTmQgqd0boBfrPjPcscZiIOdbRS0//kF1xmIgqnJlCSmIctXbFETUscZiIOdDs/8Web1ccJoLi4oTyXBtZFU1CShwi8pyIfFxELNGYUQWaEuyKw0RauTOyykSHUBPBo8BngP0i8pCInO1iTCZGHWjuIj05gfyMZK9DMVNMeV469Sd66Bsc8joUQ4iJQ1VfVtU7gCX41/leJyJvisg9IpI42nkislxE9opIjYg8MMJxEZGHnePbRGSJs79ERF4Rkd0islNE7g86J1tE1onIfuc5K9xKG3fUtnZTnpeGyIir/hozYfPz0vApHDre43UohjD6OEQkB/gc8EVgM/Bv+BPJulHKxwOPANcBlcDtIlI5rNh1QIXzWIn/ygZgEPi6qi4ClgH3BZ37ALBeVSuA9c62iQIHmrtsbWjjisBMBLXWzxEVQu3jeB74IzADuFFVb1LV/1TVrwCjfVMsBWpUtVZV+4HVwIphZVYAz6jf20CmiBSqaqOqvgegqp3AbqA46JynnddPAzeHUgfjrp7+QRrae20ornFFmd3LEVUSQiz3E1VdG7xDRJJVtU9Vq0c5pxg4ErRdD1wcQplioDHoc0qBC4B3nF0FqtoIoKqNIpI/0oeLyEr8VzHMnTt39JqZiAh0XFrHuHFDenICs2emWAd5lAi1qerbI+x7a5xzRmroHj7ZzJhlRCQdeA74qqp2jPN5H34T1cdVtVpVq/Py8sI51UxAYPbSwF2+xkRaeV6aDcmNEmNecYjIbPxXAKkicgEffNHPxN9sNZZ6oCRoew7QEGoZp9P9OeAXqvp8UJmmQHOWiBQCzePEYSbBgeYuRKA0xxKHcUd5XhprtjSgqjYAw2PjNVV9DH+H+BzgB0H7O4FvjnPuBqBCRMqAo8Bt+If0BlsDrBKR1fibsdqdhCDAT4HdqvqDEc65G3jIeX5hnDjMJKht7WZOViopiTa5oXFHeW46Hb2DHO/uJzfdhnx7aczEoapPA0+LyCdV9blw3lhVB0VkFfASEA88qao7ReRe5/hjwFrgeqAG6AHucU6/FLgT2C4iW5x933T6WR4CnhWRLwCHgVvDicu4w0ZUGbcFmkHrWrstcXhsvKaqz6rqz4FSEfmr4cdHuBoYfnwt/uQQvO+xoNcK3DfCeX9i5P4PVPU4cPVYn2sml8+n1LV2s6w8x+tQzBQWPCT3otJsj6OZ3sZrqgo0WNufkmZUjR29nBoYsuVijauKs1JJio+zZWSjwHhNVT92nr81OeGYWBS4KcuWizVuio8T5uXMsCG5USDUGwC/JyIzRSRRRNaLSKuIfNbt4ExseP8eDhuKa1xWnpdGnV1xeC7U+zj+3LmP4gb8Q2gXAH/tWlQmptS1dpOWFE+eTW5oXFaWm86h490M+Wz9cS+FmjgCExleD/xKVdtcisfEoNrWbspsckMzCcrz0hgYUupP2GSHXgo1cfxWRPYA1cB6EckDet0Ly8SS2pYuyqx/w0yCwFxo1kHurVCnVX8AuASoVtUBoJvTJyw001DvwBBHT56yyQ3NpCgLJA7rIPdUqJMcAizCfz9H8DnPRDgeE2MOt/WganNUmcmRnZbErNRE6lptziovhZQ4RORnwHxgCxBYgkuxxDHtBYbiltkVh5kEIkJZri0j67VQrziqgUrnTm9j3hdoa7bEYSZLeV4abx047nUY01qoneM7gNluBmJiU11LN3kZyWSkjLqCsDERVZ6bRmN7Lz39g16HMm2FesWRC+wSkXeBvsBOVb3JlahMzKht7barDTOpyp3JNOtau1lcNMvjaKanUBPHg24GYWJXXWs3H1tc4HUYZhoJ/KFiicM7ISUOVX1NROYBFar6sojMwD9VupnGTvb009bdb1ccZlIFFguzDnLvhDpX1V8A/x/wY2dXMfBfLsVkYsQHHeN285+ZPKlJ8RRnptqcVR4KtXP8PvyLK3UAqOp+IN+toExsqGuxdcaNN/xDcu1eDq+Emjj6VLU/sOHcBGhDc6e5utZu4uOEkqzxlp83JrLK89Kobe3G7hDwRqiJ4zUR+SaQKiLXAr8GfuteWCYW1LZ2UZKVSlJCqD9GxkRGWW4anb2DtHb1j1/YRFyov/EPAC3AduBL+JeD/Tu3gjKxobal+/2hkcZMpuAhuWbyhTrJoQ9/Z/iXVfV/qOoTodxFLiLLRWSviNSIyAMjHBcRedg5vk1ElgQde1JEmkVkx7BzHhSRoyKyxXlcH0odTGT5fMrB43YPh/FG+ftDcq2fwwtjJg7ni/1BEWkF9gB7RaRFRP5hvDcWkXjgEeA6oBK4XUQqhxW7DqhwHiuBR4OOPQUsH+Xtf6iqVc5j7XixmMg71tFL74DPEofxRFGmv4nUhuR6Y7wrjq/iH011karmqGo2cDFwqYh8bZxzlwI1qlrrdKyv5vSp2FcAz6jf20CmiBQCqOrrgC0YFaVqbUSV8VB8nFCaM8PW5fDIeInjLuB2Va0L7FDVWuCzzrGxFANHgrbrnX3hlhnJKqdp60kRyRqpgIisFJGNIrKxpaUlhLc04Qg0EZTbPRzGIzYk1zvjJY5EVW0dvlNVW/hgOdnRjLSO6PB+kVDKDPco/ineq4BG4PsjFVLVx1W1WlWr8/LyxnlLE67a1m5mJMVTMNPWGTfeKM9L53BbD4NDPq9DmXbGSxxjjXUbbxxcPVAStD0HaJhAmQ9R1SZVHXI67J/A3yRmJllti79j3NYZN14pyw2sP37K61CmnfESx/ki0jHCoxM4d5xzNwAVIlImIknAbcCaYWXWAHc5nfDLgHZVbRzrTQN9II5b8E/5biZZnc2Kazw2P++DyQ7N5BpzkkNVnfBEhqo6KCKrgJfwT4j4pKruFJF7neOP4b8f5HqgBugB7gmcLyK/Aq4AckWkHvhHVf0p8D0RqcLfpHUQ/30lZhL1DQ5Rf6KHm6uKvA7FTGOBOdJqW7u50uNYpptw1hwPmzNUdu2wfY8FvVb882CNdO7to+y/M5IxmvAdPt6DT7Gb/4ynsmYkMis10TrIPWBzRZiw2XKxJhqICOV5adZU5QFLHCZsgXs4Si1xGI/5h+Ra4phsljhM2A60dJGXkcysVFtn3Hhrfl46xzp66e6z9ccnkyUOE7aa5i7Osv4NEwWCl5E1k8cShwmLqnKguYuz8i1xGO+V25BcT1jiMGFp7uyjs2/QEoeJCrb+uDcscZiw1DT7hz5a4jDRICUxsP64DcmdTJY4TFgscZhoY0NyJ58lDhOWAy1dZCQnkJ9hkxua6BAYkmvrj08eSxwmLDXNXczPT7fJDU3UKM9No7PP1h+fTJY4TFhqbESViTJlztBwm3pk8ljiMCHr6B2gubPPEoeJKuV2L8eks8RhQhboGJ9vN/+ZKFKUmUpyQhwH7Ipj0ljiMCGzEVUmGsXHCfPz0tnXZIljsljiMCE70NxFUnwcJVmpXodizIcsKEhnX1On12FMG5Y4TMhqmrsoy00jId5+bEx0WTA7g8b2Xjp6B7wOZVqwbwATspoWG1FlotOC/AwA9ltz1aSwxGFCcqp/iMNtPZY4TFRaUBBIHNZcNRlcTRwislxE9opIjYg8MMJxEZGHnePbRGRJ0LEnRaRZRHYMOydbRNaJyH7nOcvNOhi//c2dqMKiwgyvQzHmNHOyUklNjGevJY5J4VriEJF44BHgOqASuF1EKocVuw6ocB4rgUeDjj0FLB/hrR8A1qtqBbDe2TYu23PM/wu5cPZMjyMx5nRxcUJFQbo1VU0SN684lgI1qlqrqv3AamDFsDIrgGfU720gU0QKAVT1daBthPddATztvH4auNmN4M2H7WnsJCUxjrnZM7wOxZgRVeRn2MiqSeJm4igGjgRt1zv7wi0zXIGqNgI4z/kjFRKRlSKyUUQ2trS0hBW4Od3epg4WFGQQH2dzVJnotKAgnebOPk722JxVbnMzcYz0DTN8+spQykyIqj6uqtWqWp2XlxeJt5zW9h7r5OzZ1r9holegg9xuBHSfm4mjHigJ2p4DNEygzHBNgeYs57n5DOM042jp7KO1q9/6N0xUWzA7kDisucptbiaODUCFiJSJSBJwG7BmWJk1wF3O6KplQHugGWoMa4C7ndd3Ay9EMmhzur1Ox7hdcZhoVjQrhfTkBBuSOwlcSxyqOgisAl4CdgPPqupOEblXRO51iq0FaoEa4Angy4HzReRXwFvAQhGpF5EvOIceAq4Vkf3Atc62cdGeYx0ALLTEYaKYiLCgIJ3dxyxxuC3BzTdX1bX4k0PwvseCXitw3yjn3j7K/uPA1REM04xj77FOctOTyE23Vf9MdFtcNIv/2nwUn0+Js4EcrrE7x8249hzrtKsNExMqi2bS2TdI/YlTXocypVniMGMa8in7mjo52zrGTQyoLPT/nO5qbPc4kqnNEocZU11rF32DPusYNzFh4Wz/vUY7Gzq8DmVKs8RhxrT9qP8vt3PnzPI4EmPGl5IYz/y8NHZZ4nCVJQ4zpu31HaQkxnGWLRdrYkRl4Ux2NVricJMlDjOmHUfbWVQ40xZvMjFjcdEsGtt7aeu2qUfcYt8GZlQ+n7KzoZ1zi62ZysSOyiKng9yaq1xjicOMqra1m+7+Ic6xxGFiSGBk1Y4GG1nlFkscZlQ7Ah3jljhMDMlKS6IkO5WtR056HcqUZYnDjGr70XaSE+KosOViTYypKsliiyUO11jiMKPabh3jJkZVlWTS2N5LU0ev16FMSfaNYEY05FN2HrWOcRObqkoyAdh8+KSncUxVljjMiPYe66S7f4gL52V5HYoxYVtcNJPEeLHmKpdY4jAj2nT4BIAlDhOTUhLjWVQ4ky1HTngdypRkicOM6L1DJ8jLSGZOVqrXoRgzIVUlmWyvb2fIF5HVqE0QSxxmRJsOneDCuVmI2JoGJjZVlWTS3T/E/mZb2CnSLHGY0zR39nK4rYcl8zK9DsWYCVsy19/MuvGgNVdFmiUOc5r3Dp0ErH/DxLZ5OTOYPTOFt2uPex3KlONq4hCR5SKyV0RqROSBEY6LiDzsHN8mIkvGO1dEHhSRoyKyxXlc72YdpqN369pITohjcZENxTWxS0S4uDybd+ra8K9SbSLFtcQhIvHAI8B1QCVwu4hUDit2HVDhPFYCj4Z47g9Vtcp5rMVE1JsHWqkuzSIlMd7rUIw5I8vKc2jp7KO2tdvrUKYUN684lgI1qlqrqv3AamDFsDIrgGfU720gU0QKQzzXuKC1q489xzr5yPxcr0Mx5oxdXJYNwDu1bR5HMrW4mTiKgSNB2/XOvlDKjHfuKqdp60kRsYb4CAq0B39kfo7HkRhz5spy08jPSLZ+jghzM3GMNI5zeEPjaGXGOvdRYD5QBTQC3x/xw0VWishGEdnY0tISUsAG3jxwnPTkBJtqxEwJIsIl83N480ArPrufI2LcTBz1QEnQ9hygIcQyo56rqk2qOqSqPuAJ/M1ap1HVx1W1WlWr8/Lyzqgi08lbB45zcVm2TWxopoyPLsijtaufnbawU8S4+e2wAagQkTIRSQJuA9YMK7MGuMsZXbUMaFfVxrHOdfpAAm4BdrhYh2nlYGs3da3dXFZh/Rtm6rh8gf8Px1f3NnscydThWuJQ1UFgFfASsBt4VlV3isi9InKvU2wtUAvU4L96+PJY5zrnfE9EtovINuBK4Gtu1WG6eXl3EwDXLCrwOBJjIic3PZnz58zi1X3WZB0pCW6+uTNUdu2wfY8FvVbgvlDPdfbfGeEwjWP97mYWFKRTkj3D61CMiaiPLsznR3/Yz8mefjJnJHkdTsyzhmwDQPupATYcbONqu9owU9CVC/PwKby61646IsEShwHgtX0tDPqUaxblex2KMRF3/pxMZs9M4cVtjV6HMiVY4jAAvLi1gbyMZKpK7LYYM/XExQkfP6+Q1/e10H5qwOtwYp4lDkN7zwCv7m3hpvOLiI+zadTN1HTDeYX0D/lYt6vJ61BiniUOw9odjfQP+bi5aviN/cZMHVUlmRRnpvLituG3k5lwWeIw/GbzUcrz0jineKbXoRjjGhFhRVURf9zfSmP7Ka/DiWmWOKa5utZu3q1r4xMXFNtqf2bKu+2iufhUWf3ukfELm1FZ4pjmfvbWIRLjhU9dVDJ+YWNi3NycGVxekcfqDYcZHPJ5HU7MssQxjXX3DfLrTUe4/txC8jNSvA7HmElxx8Vzaeros07yM2CJYxr75TuH6ewd5O6PlHodijGT5qqz8ynNmcGPXqmxlQEnyBLHNHWqf4gfv36Ay87KZclcu3fDTB8J8XGsuqqCnQ0dvLzbJj6cCEsc09R/vFlHa1c/919T4XUoxky6m6uKmJczgx+u28eQrdMRNksc09Cx9l5+9IcarllUwEWl2V6HY8ykS4iP46+uXcCuxg5+9e5hr8OJOZY4phlV5Vu/3cmgT/mHGyq9DscYz9x0fhGXlOfwvd/voamj1+twYooljmnm15vq+d2OY3ztmgXMzbHp0830JSJ8+5ZzGBhSvvafW6zJKgyWOKaRzYdP8A8v7GBZeTYrLy/3OhxjPDc/L50Hb6rkzQPHeeh3u70OJ2a4upCTiR57j3Xyxac3kp+Rwo8+s8QmMzTG8anqEnY1dPDEH+vISkviy1ec5XVIUc8SxzTwx/0trPrlZlIT43nqnovITU/2OiRjooaI8I83LuZEzwDf+/1emtp7+fsbKkmItwaZ0VjimMLaTw3w8Pr9/PRPdVTkp/Pk5y6yZWGNGUFcnPDDT1dRMDOZJ/5Yx6bDJ/jOLedx7pxZXocWlVxNqSKyXET2ikiNiDwwwnERkYed49tEZMl454pItoisE5H9zrPdvTbMgZYuvvO73Xz0X17hyTfq+MzFc1mz6jJLGsaMIT5O+NuPV/LoHUto6ujjxh/9ic8/tYF1u5roHRjyOryoIm7dci8i8cA+4FqgHtgA3K6qu4LKXA98BbgeuBj4N1W9eKxzReR7QJuqPuQklCxV/ZuxYqmurtaNGzdGvpIe8fmU7v5BOnoHOdnTT/2JUxw63s3eY128U3ec+hOniI8Trj47n/uvqWBxkf3VZEw42k8N8MybB3nqzYMc7+4nLSmeC+ZmcX7JLMpy0ynOTKUoM4WZKYmkJSeQlDA1m7VEZJOqVg/f72ZT1VKgRlVrnQBWAyuAXUFlVgDPqD97vS0imSJSCJSOce4K4Arn/KeBV4ExE8dEPbx+Py9sOQqAOv8JpFlVRYFA3lUU1Q+2g8vglAuUCbyf6vvv7Bzn/blzAseDtwOf39M/yEgjB3PTk6iel80XLyvzT1w40yYuNGYiZqUm8pWrK7j3ivm8UdPKy7ub2Hz4JI+9VjvisN2khDhSE+OJjxP/Q+SD13FCOCsWhFo01GUQ/p9bzmVpWWRv9HUzcRQDwZPe1+O/qhivTPE45xaoaiOAqjaKSP5IHy4iK4GVAHPnzp1QBQpmJnP27Jnv/0uK/33f/4cV+WBf4DgCgRIfHA+c7/8B+uDfW94v80F5CSr/4R+OwPG05HhmpiSSkZLAzNREijNTKc1NY1Zq4oTqaYwZWWJ8HFcszOeKhf6vmd6BIRrbezl64hSN7afo6huku2+Qzr5BevuHGFJlyAdDPh9DPvCpMujTkCdTDLn9J4yGorTk+NALh8jNxDFSOhxe3dHKhHLumFT1ceBx8DdVhXNuwKcvmsunL5pY0jHGTD0pifGU5aZRlpvmdSiecrNhrh4IXh1oDjB8sd/Ryox1bpPTnIXzbNNbGmPMJHIzcWwAKkSkTESSgNuANcPKrAHuckZXLQPanWaosc5dA9ztvL4beMHFOhhjjBnGtaYqVR0UkVXAS0A88KSq7hSRe53jjwFr8Y+oqgF6gHvGOtd564eAZ0XkC8Bh4Fa36mCMMeZ0rg3HjSZTbTiuMcZMhtGG407NwcfGGGNcY4nDGGNMWCxxGGOMCYslDmOMMWGZFp3jItICHPI6DiAXaPU6iAiy+kS/qVanqVYfiO46zVPVvOE7p0XiiBYisnGkEQqxyuoT/aZanaZafSA262RNVcYYY8JiicMYY0xYLHFMrse9DiDCrD7Rb6rVaarVB2KwTtbHYYwxJix2xWGMMSYsljiMMcaExRKHy0TkVhHZKSI+EakeduwbIlIjIntF5GNexRguEVnuxFzjrPsec0TkSRFpFpEdQfuyRWSdiOx3nrO8jDEcIlIiIq+IyG7n5+1+Z38s1ylFRN4Vka1Onb7l7I/ZOgGISLyIbBaRF53tmKuPJQ737QA+AbwevFNEKvGvM7IYWA78u4hEfo3HCHNifAS4DqgEbnfqEmuewv//PdgDwHpVrQDWO9uxYhD4uqouApYB9zn/LrFcpz7gKlU9H6gCljvr9sRynQDuB3YHbcdcfSxxuExVd6vq3hEOrQBWq2qfqtbhX5Nk6eRGNyFLgRpVrVXVfmA1/rrEFFV9HWgbtnsF8LTz+mng5smM6UyoaqOqvue87sT/xVRMbNdJVbXL2Ux0HkoM10lE5gAfB34StDvm6mOJwzvFwJGg7XpnX7SL1bhDUeCsQInznO9xPBMiIqXABcA7xHidnGadLfiXiF6nqrFep/8X+F+AL2hfzNXHtRUApxMReRmYPcKhv1XV0Za2lRH2xcLY6FiNe1oQkXTgOeCrqtohMtI/V+xQ1SGgSkQygd+IyDkehzRhInID0Kyqm0TkCo/DOSOWOCJAVa+ZwGn1QEnQ9hygITIRuSpW4w5Fk4gUqmqjiBTi/ys3ZohIIv6k8QtVfd7ZHdN1ClDVkyLyKv5+qVit06XATSJyPZACzBSRnxOD9bGmKu+sAW4TkWQRKQMqgHc9jikUG4AKESkTkST8HfxrPI4pUtYAdzuv7wZGu1qMOuK/tPgpsFtVfxB0KJbrlOdcaSAiqcA1wB5itE6q+g1VnaOqpfh/b/6gqp8lFuujqvZw8QHcgv+v9D6gCXgp6NjfAgeAvcB1XscaRp2uB/Y5sf+t1/FMsA6/AhqBAeff5wtADv5RLfud52yv4wyjPpfhbzLcBmxxHtfHeJ3OAzY7ddoB/IOzP2brFFS3K4AXY7U+NuWIMcaYsFhTlTHGmLBY4jDGGBMWSxzGGGPCYonDGGNMWCxxGGOMCYslDmOMMWGxxGGMMSYs/z/YJNWe3ximJwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df1['id'].value_counts().sort_index().plot(kind='density')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also generate a validation set. Then, we dump the data `DataSeqLoader`, which inherites `keras.utils.Sequence` class. It is a structure that sequentialize data into batches of correct shape and format (similar to dataset & dataloader in PyTorch). \n",
    "\n",
    "In our usage, we reformat the tabular feature data into `num_predictors x (batch_size, timesteps, 1)`. We can change the argument `many_to_one: bool` to control the output data's shape: `(batch_size, 1)` for `True` and `(batch_size, timesteps, 1)` for `False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/scots/Desktop/Duke Univeristy/Research/EHR missing data/embedding/embedding_missingdata/data_utils.py:100: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  self._rawX[var] = self._rawX[var].fillna(\"Missing\")\n",
      "100%|██████████| 1000/1000 [00:10<00:00, 94.44it/s]\n",
      "/Users/scots/Desktop/Duke Univeristy/Research/EHR missing data/embedding/embedding_missingdata/data_utils.py:100: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  self._rawX[var] = self._rawX[var].fillna(\"Missing\")\n",
      "100%|██████████| 400/400 [00:04<00:00, 95.11it/s] \n"
     ]
    }
   ],
   "source": [
    "df2 = data_gen(n=400, p=20, max_t=30)\n",
    "dl1 = DataSeqLoader(\n",
    "    X=df1.drop([\"id\", \"y\"], axis=1),\n",
    "    y=df1[\"y\"],\n",
    "    ids=df1[\"id\"],\n",
    "    max_t=30,\n",
    "    batch_size=8,\n",
    "    many_to_one=False,\n",
    ")\n",
    "dl2 = DataSeqLoader(\n",
    "    X=df2.drop([\"id\", \"y\"], axis=1),\n",
    "    y=df2[\"y\"],\n",
    "    ids=df2[\"id\"],\n",
    "    max_t=30,\n",
    "    batch_size=8,\n",
    "    many_to_one=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C1': 6, 'C2': 3}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl1.categorical_vars_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(8, 4, 5), dtype=float32, numpy=\n",
       "array([[[0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.]],\n",
       "\n",
       "       [[1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0., 0.]]], dtype=float32)>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = dl1.data_seqs[3][0][0][-1]\n",
    "TimeDistributedOneHotEncoding(num_tokens=5)(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model did not implement padding.\n",
    "\n",
    "In theory, LSTM/RNN models share weights along the time dimension, allowing input data to have varying timesteps. However, in practice, samples in the same batch must share the same timesteps during the training process (because of the way TF/Keras was built). Some engieering tircks has been implemented to ensure that when construct the dataloader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43.92810535176964"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "10 * ((np.log(10)/ np.log(3)) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, None, 6)\n",
      "(None, None, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-25 11:50:45.417074: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-01-25 11:50:45.419529: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-01-25 11:50:45.421854: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-01-25 11:50:45.702390: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-01-25 11:50:45.704861: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-01-25 11:50:45.706780: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-01-25 11:50:45.946099: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-01-25 11:50:45.948454: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-01-25 11:50:45.949990: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    }
   ],
   "source": [
    "em = EmbeddingLSTMModel(dl1, False, 2)\n",
    "em.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_14\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " x0_indct (InputLayer)          [(None, None, 1)]    0           []                               \n",
      "                                                                                                  \n",
      " x1_indct (InputLayer)          [(None, None, 1)]    0           []                               \n",
      "                                                                                                  \n",
      " x2_indct (InputLayer)          [(None, None, 1)]    0           []                               \n",
      "                                                                                                  \n",
      " x3_indct (InputLayer)          [(None, None, 1)]    0           []                               \n",
      "                                                                                                  \n",
      " x4_indct (InputLayer)          [(None, None, 1)]    0           []                               \n",
      "                                                                                                  \n",
      " x5_indct (InputLayer)          [(None, None, 1)]    0           []                               \n",
      "                                                                                                  \n",
      " x6_indct (InputLayer)          [(None, None, 1)]    0           []                               \n",
      "                                                                                                  \n",
      " x7_indct (InputLayer)          [(None, None, 1)]    0           []                               \n",
      "                                                                                                  \n",
      " x8_indct (InputLayer)          [(None, None, 1)]    0           []                               \n",
      "                                                                                                  \n",
      " x9_indct (InputLayer)          [(None, None, 1)]    0           []                               \n",
      "                                                                                                  \n",
      " x10_indct (InputLayer)         [(None, None, 1)]    0           []                               \n",
      "                                                                                                  \n",
      " x11_indct (InputLayer)         [(None, None, 1)]    0           []                               \n",
      "                                                                                                  \n",
      " x12_indct (InputLayer)         [(None, None, 1)]    0           []                               \n",
      "                                                                                                  \n",
      " x13_indct (InputLayer)         [(None, None, 1)]    0           []                               \n",
      "                                                                                                  \n",
      " x14_indct (InputLayer)         [(None, None, 1)]    0           []                               \n",
      "                                                                                                  \n",
      " x15_indct (InputLayer)         [(None, None, 1)]    0           []                               \n",
      "                                                                                                  \n",
      " x16_indct (InputLayer)         [(None, None, 1)]    0           []                               \n",
      "                                                                                                  \n",
      " x17_indct (InputLayer)         [(None, None, 1)]    0           []                               \n",
      "                                                                                                  \n",
      " x18_indct (InputLayer)         [(None, None, 1)]    0           []                               \n",
      "                                                                                                  \n",
      " x19_indct (InputLayer)         [(None, None, 1)]    0           []                               \n",
      "                                                                                                  \n",
      " x0_indctr_embedded (TimeDistri  (None, None, 1, 2)  4           ['x0_indct[0][0]']               \n",
      " buted)                                                                                           \n",
      "                                                                                                  \n",
      " x1_indctr_embedded (TimeDistri  (None, None, 1, 2)  4           ['x1_indct[0][0]']               \n",
      " buted)                                                                                           \n",
      "                                                                                                  \n",
      " x2_indctr_embedded (TimeDistri  (None, None, 1, 2)  4           ['x2_indct[0][0]']               \n",
      " buted)                                                                                           \n",
      "                                                                                                  \n",
      " x3_indctr_embedded (TimeDistri  (None, None, 1, 2)  4           ['x3_indct[0][0]']               \n",
      " buted)                                                                                           \n",
      "                                                                                                  \n",
      " x4_indctr_embedded (TimeDistri  (None, None, 1, 2)  4           ['x4_indct[0][0]']               \n",
      " buted)                                                                                           \n",
      "                                                                                                  \n",
      " x5_indctr_embedded (TimeDistri  (None, None, 1, 2)  4           ['x5_indct[0][0]']               \n",
      " buted)                                                                                           \n",
      "                                                                                                  \n",
      " x6_indctr_embedded (TimeDistri  (None, None, 1, 2)  4           ['x6_indct[0][0]']               \n",
      " buted)                                                                                           \n",
      "                                                                                                  \n",
      " x7_indctr_embedded (TimeDistri  (None, None, 1, 2)  4           ['x7_indct[0][0]']               \n",
      " buted)                                                                                           \n",
      "                                                                                                  \n",
      " x8_indctr_embedded (TimeDistri  (None, None, 1, 2)  4           ['x8_indct[0][0]']               \n",
      " buted)                                                                                           \n",
      "                                                                                                  \n",
      " x9_indctr_embedded (TimeDistri  (None, None, 1, 2)  4           ['x9_indct[0][0]']               \n",
      " buted)                                                                                           \n",
      "                                                                                                  \n",
      " x10_indctr_embedded (TimeDistr  (None, None, 1, 2)  4           ['x10_indct[0][0]']              \n",
      " ibuted)                                                                                          \n",
      "                                                                                                  \n",
      " x11_indctr_embedded (TimeDistr  (None, None, 1, 2)  4           ['x11_indct[0][0]']              \n",
      " ibuted)                                                                                          \n",
      "                                                                                                  \n",
      " x12_indctr_embedded (TimeDistr  (None, None, 1, 2)  4           ['x12_indct[0][0]']              \n",
      " ibuted)                                                                                          \n",
      "                                                                                                  \n",
      " x13_indctr_embedded (TimeDistr  (None, None, 1, 2)  4           ['x13_indct[0][0]']              \n",
      " ibuted)                                                                                          \n",
      "                                                                                                  \n",
      " x14_indctr_embedded (TimeDistr  (None, None, 1, 2)  4           ['x14_indct[0][0]']              \n",
      " ibuted)                                                                                          \n",
      "                                                                                                  \n",
      " x15_indctr_embedded (TimeDistr  (None, None, 1, 2)  4           ['x15_indct[0][0]']              \n",
      " ibuted)                                                                                          \n",
      "                                                                                                  \n",
      " x16_indctr_embedded (TimeDistr  (None, None, 1, 2)  4           ['x16_indct[0][0]']              \n",
      " ibuted)                                                                                          \n",
      "                                                                                                  \n",
      " x17_indctr_embedded (TimeDistr  (None, None, 1, 2)  4           ['x17_indct[0][0]']              \n",
      " ibuted)                                                                                          \n",
      "                                                                                                  \n",
      " x18_indctr_embedded (TimeDistr  (None, None, 1, 2)  4           ['x18_indct[0][0]']              \n",
      " ibuted)                                                                                          \n",
      "                                                                                                  \n",
      " x19_indctr_embedded (TimeDistr  (None, None, 1, 2)  4           ['x19_indct[0][0]']              \n",
      " ibuted)                                                                                          \n",
      "                                                                                                  \n",
      " x0 (InputLayer)                [(None, None, 1)]    0           []                               \n",
      "                                                                                                  \n",
      " x0_indctr_embedded_reshape (Ti  (None, None, 2)     0           ['x0_indctr_embedded[0][0]']     \n",
      " meDistributed)                                                                                   \n",
      "                                                                                                  \n",
      " x1 (InputLayer)                [(None, None, 1)]    0           []                               \n",
      "                                                                                                  \n",
      " x1_indctr_embedded_reshape (Ti  (None, None, 2)     0           ['x1_indctr_embedded[0][0]']     \n",
      " meDistributed)                                                                                   \n",
      "                                                                                                  \n",
      " x2 (InputLayer)                [(None, None, 1)]    0           []                               \n",
      "                                                                                                  \n",
      " x2_indctr_embedded_reshape (Ti  (None, None, 2)     0           ['x2_indctr_embedded[0][0]']     \n",
      " meDistributed)                                                                                   \n",
      "                                                                                                  \n",
      " x3 (InputLayer)                [(None, None, 1)]    0           []                               \n",
      "                                                                                                  \n",
      " x3_indctr_embedded_reshape (Ti  (None, None, 2)     0           ['x3_indctr_embedded[0][0]']     \n",
      " meDistributed)                                                                                   \n",
      "                                                                                                  \n",
      " x4 (InputLayer)                [(None, None, 1)]    0           []                               \n",
      "                                                                                                  \n",
      " x4_indctr_embedded_reshape (Ti  (None, None, 2)     0           ['x4_indctr_embedded[0][0]']     \n",
      " meDistributed)                                                                                   \n",
      "                                                                                                  \n",
      " x5 (InputLayer)                [(None, None, 1)]    0           []                               \n",
      "                                                                                                  \n",
      " x5_indctr_embedded_reshape (Ti  (None, None, 2)     0           ['x5_indctr_embedded[0][0]']     \n",
      " meDistributed)                                                                                   \n",
      "                                                                                                  \n",
      " x6 (InputLayer)                [(None, None, 1)]    0           []                               \n",
      "                                                                                                  \n",
      " x6_indctr_embedded_reshape (Ti  (None, None, 2)     0           ['x6_indctr_embedded[0][0]']     \n",
      " meDistributed)                                                                                   \n",
      "                                                                                                  \n",
      " x7 (InputLayer)                [(None, None, 1)]    0           []                               \n",
      "                                                                                                  \n",
      " x7_indctr_embedded_reshape (Ti  (None, None, 2)     0           ['x7_indctr_embedded[0][0]']     \n",
      " meDistributed)                                                                                   \n",
      "                                                                                                  \n",
      " x8 (InputLayer)                [(None, None, 1)]    0           []                               \n",
      "                                                                                                  \n",
      " x8_indctr_embedded_reshape (Ti  (None, None, 2)     0           ['x8_indctr_embedded[0][0]']     \n",
      " meDistributed)                                                                                   \n",
      "                                                                                                  \n",
      " x9 (InputLayer)                [(None, None, 1)]    0           []                               \n",
      "                                                                                                  \n",
      " x9_indctr_embedded_reshape (Ti  (None, None, 2)     0           ['x9_indctr_embedded[0][0]']     \n",
      " meDistributed)                                                                                   \n",
      "                                                                                                  \n",
      " x10 (InputLayer)               [(None, None, 1)]    0           []                               \n",
      "                                                                                                  \n",
      " x10_indctr_embedded_reshape (T  (None, None, 2)     0           ['x10_indctr_embedded[0][0]']    \n",
      " imeDistributed)                                                                                  \n",
      "                                                                                                  \n",
      " x11 (InputLayer)               [(None, None, 1)]    0           []                               \n",
      "                                                                                                  \n",
      " x11_indctr_embedded_reshape (T  (None, None, 2)     0           ['x11_indctr_embedded[0][0]']    \n",
      " imeDistributed)                                                                                  \n",
      "                                                                                                  \n",
      " x12 (InputLayer)               [(None, None, 1)]    0           []                               \n",
      "                                                                                                  \n",
      " x12_indctr_embedded_reshape (T  (None, None, 2)     0           ['x12_indctr_embedded[0][0]']    \n",
      " imeDistributed)                                                                                  \n",
      "                                                                                                  \n",
      " x13 (InputLayer)               [(None, None, 1)]    0           []                               \n",
      "                                                                                                  \n",
      " x13_indctr_embedded_reshape (T  (None, None, 2)     0           ['x13_indctr_embedded[0][0]']    \n",
      " imeDistributed)                                                                                  \n",
      "                                                                                                  \n",
      " x14 (InputLayer)               [(None, None, 1)]    0           []                               \n",
      "                                                                                                  \n",
      " x14_indctr_embedded_reshape (T  (None, None, 2)     0           ['x14_indctr_embedded[0][0]']    \n",
      " imeDistributed)                                                                                  \n",
      "                                                                                                  \n",
      " x15 (InputLayer)               [(None, None, 1)]    0           []                               \n",
      "                                                                                                  \n",
      " x15_indctr_embedded_reshape (T  (None, None, 2)     0           ['x15_indctr_embedded[0][0]']    \n",
      " imeDistributed)                                                                                  \n",
      "                                                                                                  \n",
      " x16 (InputLayer)               [(None, None, 1)]    0           []                               \n",
      "                                                                                                  \n",
      " x16_indctr_embedded_reshape (T  (None, None, 2)     0           ['x16_indctr_embedded[0][0]']    \n",
      " imeDistributed)                                                                                  \n",
      "                                                                                                  \n",
      " x17 (InputLayer)               [(None, None, 1)]    0           []                               \n",
      "                                                                                                  \n",
      " x17_indctr_embedded_reshape (T  (None, None, 2)     0           ['x17_indctr_embedded[0][0]']    \n",
      " imeDistributed)                                                                                  \n",
      "                                                                                                  \n",
      " x18 (InputLayer)               [(None, None, 1)]    0           []                               \n",
      "                                                                                                  \n",
      " x18_indctr_embedded_reshape (T  (None, None, 2)     0           ['x18_indctr_embedded[0][0]']    \n",
      " imeDistributed)                                                                                  \n",
      "                                                                                                  \n",
      " x19 (InputLayer)               [(None, None, 1)]    0           []                               \n",
      "                                                                                                  \n",
      " x19_indctr_embedded_reshape (T  (None, None, 2)     0           ['x19_indctr_embedded[0][0]']    \n",
      " imeDistributed)                                                                                  \n",
      "                                                                                                  \n",
      " c1 (InputLayer)                [(None, None, 1)]    0           []                               \n",
      "                                                                                                  \n",
      " c2 (InputLayer)                [(None, None, 1)]    0           []                               \n",
      "                                                                                                  \n",
      " x0_cont_rescale (TimeDistribut  (None, None, 2)     0           ['x0[0][0]',                     \n",
      " ed)                                                              'x0_indctr_embedded_reshape[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " x1_cont_rescale (TimeDistribut  (None, None, 2)     0           ['x1[0][0]',                     \n",
      " ed)                                                              'x1_indctr_embedded_reshape[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " x2_cont_rescale (TimeDistribut  (None, None, 2)     0           ['x2[0][0]',                     \n",
      " ed)                                                              'x2_indctr_embedded_reshape[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " x3_cont_rescale (TimeDistribut  (None, None, 2)     0           ['x3[0][0]',                     \n",
      " ed)                                                              'x3_indctr_embedded_reshape[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " x4_cont_rescale (TimeDistribut  (None, None, 2)     0           ['x4[0][0]',                     \n",
      " ed)                                                              'x4_indctr_embedded_reshape[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " x5_cont_rescale (TimeDistribut  (None, None, 2)     0           ['x5[0][0]',                     \n",
      " ed)                                                              'x5_indctr_embedded_reshape[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " x6_cont_rescale (TimeDistribut  (None, None, 2)     0           ['x6[0][0]',                     \n",
      " ed)                                                              'x6_indctr_embedded_reshape[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " x7_cont_rescale (TimeDistribut  (None, None, 2)     0           ['x7[0][0]',                     \n",
      " ed)                                                              'x7_indctr_embedded_reshape[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " x8_cont_rescale (TimeDistribut  (None, None, 2)     0           ['x8[0][0]',                     \n",
      " ed)                                                              'x8_indctr_embedded_reshape[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " x9_cont_rescale (TimeDistribut  (None, None, 2)     0           ['x9[0][0]',                     \n",
      " ed)                                                              'x9_indctr_embedded_reshape[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " x10_cont_rescale (TimeDistribu  (None, None, 2)     0           ['x10[0][0]',                    \n",
      " ted)                                                             'x10_indctr_embedded_reshape[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " x11_cont_rescale (TimeDistribu  (None, None, 2)     0           ['x11[0][0]',                    \n",
      " ted)                                                             'x11_indctr_embedded_reshape[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " x12_cont_rescale (TimeDistribu  (None, None, 2)     0           ['x12[0][0]',                    \n",
      " ted)                                                             'x12_indctr_embedded_reshape[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " x13_cont_rescale (TimeDistribu  (None, None, 2)     0           ['x13[0][0]',                    \n",
      " ted)                                                             'x13_indctr_embedded_reshape[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " x14_cont_rescale (TimeDistribu  (None, None, 2)     0           ['x14[0][0]',                    \n",
      " ted)                                                             'x14_indctr_embedded_reshape[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " x15_cont_rescale (TimeDistribu  (None, None, 2)     0           ['x15[0][0]',                    \n",
      " ted)                                                             'x15_indctr_embedded_reshape[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " x16_cont_rescale (TimeDistribu  (None, None, 2)     0           ['x16[0][0]',                    \n",
      " ted)                                                             'x16_indctr_embedded_reshape[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " x17_cont_rescale (TimeDistribu  (None, None, 2)     0           ['x17[0][0]',                    \n",
      " ted)                                                             'x17_indctr_embedded_reshape[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " x18_cont_rescale (TimeDistribu  (None, None, 2)     0           ['x18[0][0]',                    \n",
      " ted)                                                             'x18_indctr_embedded_reshape[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " x19_cont_rescale (TimeDistribu  (None, None, 2)     0           ['x19[0][0]',                    \n",
      " ted)                                                             'x19_indctr_embedded_reshape[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " c1_embedded (TimeDistributed)  (None, None, 1, 2)   12          ['c1[0][0]']                     \n",
      "                                                                                                  \n",
      " c2_embedded (TimeDistributed)  (None, None, 1, 2)   6           ['c2[0][0]']                     \n",
      "                                                                                                  \n",
      " transformed_input_cont (TimeDi  (None, None, 40)    0           ['x0_cont_rescale[0][0]',        \n",
      " stributed)                                                       'x1_cont_rescale[0][0]',        \n",
      "                                                                  'x2_cont_rescale[0][0]',        \n",
      "                                                                  'x3_cont_rescale[0][0]',        \n",
      "                                                                  'x4_cont_rescale[0][0]',        \n",
      "                                                                  'x5_cont_rescale[0][0]',        \n",
      "                                                                  'x6_cont_rescale[0][0]',        \n",
      "                                                                  'x7_cont_rescale[0][0]',        \n",
      "                                                                  'x8_cont_rescale[0][0]',        \n",
      "                                                                  'x9_cont_rescale[0][0]',        \n",
      "                                                                  'x10_cont_rescale[0][0]',       \n",
      "                                                                  'x11_cont_rescale[0][0]',       \n",
      "                                                                  'x12_cont_rescale[0][0]',       \n",
      "                                                                  'x13_cont_rescale[0][0]',       \n",
      "                                                                  'x14_cont_rescale[0][0]',       \n",
      "                                                                  'x15_cont_rescale[0][0]',       \n",
      "                                                                  'x16_cont_rescale[0][0]',       \n",
      "                                                                  'x17_cont_rescale[0][0]',       \n",
      "                                                                  'x18_cont_rescale[0][0]',       \n",
      "                                                                  'x19_cont_rescale[0][0]']       \n",
      "                                                                                                  \n",
      " c1embedded_reshape (TimeDistri  (None, None, 2)     0           ['c1_embedded[0][0]']            \n",
      " buted)                                                                                           \n",
      "                                                                                                  \n",
      " c2embedded_reshape (TimeDistri  (None, None, 2)     0           ['c2_embedded[0][0]']            \n",
      " buted)                                                                                           \n",
      "                                                                                                  \n",
      " last_concat (TimeDistributed)  (None, None, 44)     0           ['transformed_input_cont[0][0]', \n",
      "                                                                  'c1embedded_reshape[0][0]',     \n",
      "                                                                  'c2embedded_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " lstm0 (LSTM)                   (None, None, 128)    88576       ['last_concat[0][0]']            \n",
      "                                                                                                  \n",
      " lstm1 (LSTM)                   (None, None, 128)    131584      ['lstm0[0][0]']                  \n",
      "                                                                                                  \n",
      " lstm2 (LSTM)                   (None, None, 128)    131584      ['lstm1[0][0]']                  \n",
      "                                                                                                  \n",
      " output (TimeDistributed)       (None, None, 1)      129         ['lstm2[0][0]']                  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 351,971\n",
      "Trainable params: 351,971\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "em.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-25 11:50:33.877581: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2024-01-25 11:50:35.534068: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-01-25 11:50:35.535805: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-01-25 11:50:35.538085: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-01-25 11:50:35.751825: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-01-25 11:50:35.754530: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-01-25 11:50:35.756547: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-01-25 11:50:35.988380: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-01-25 11:50:35.991457: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-01-25 11:50:35.995750: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[96], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mem\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdl2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./example.hdf5\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric_curve\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mROC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Duke Univeristy/Research/EHR missing data/embedding/embedding_missingdata/nn_models.py:84\u001b[0m, in \u001b[0;36mNN.fit\u001b[0;34m(self, val_data, filepath, metric_curve, epochs, lr)\u001b[0m\n\u001b[1;32m     76\u001b[0m early_stopping \u001b[38;5;241m=\u001b[39m EarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     77\u001b[0m save_best \u001b[38;5;241m=\u001b[39m ModelCheckpoint(\n\u001b[1;32m     78\u001b[0m     filepath,\n\u001b[1;32m     79\u001b[0m     save_best_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     82\u001b[0m     save_weights_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     83\u001b[0m )\n\u001b[0;32m---> 84\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_best\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/missing/lib/python3.10/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/missing/lib/python3.10/site-packages/keras/engine/training.py:1685\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1677\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1678\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1679\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1682\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1683\u001b[0m ):\n\u001b[1;32m   1684\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1685\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1686\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1687\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/missing/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/missing/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:894\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    891\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    893\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 894\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    896\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    897\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/missing/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:942\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    939\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    940\u001b[0m   \u001b[38;5;66;03m# This is the first call of __call__, so we have to initialize.\u001b[39;00m\n\u001b[1;32m    941\u001b[0m   initializers \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 942\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_initializers_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitializers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    944\u001b[0m   \u001b[38;5;66;03m# At this point we know that the initialization is complete (or less\u001b[39;00m\n\u001b[1;32m    945\u001b[0m   \u001b[38;5;66;03m# interestingly an exception was raised) so we no longer need a lock.\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/missing/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:763\u001b[0m, in \u001b[0;36mFunction._initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    760\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lifted_initializer_graph \u001b[38;5;241m=\u001b[39m lifted_initializer_graph\n\u001b[1;32m    761\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph_deleter \u001b[38;5;241m=\u001b[39m FunctionDeleter(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lifted_initializer_graph)\n\u001b[1;32m    762\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concrete_variable_creation_fn \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 763\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_fn\u001b[49m\u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    764\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_concrete_function_internal_garbage_collected\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    765\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    767\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvalid_creator_scope\u001b[39m(\u001b[38;5;241m*\u001b[39munused_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39munused_kwds):\n\u001b[1;32m    768\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Disables variable creation.\"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/missing/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:171\u001b[0m, in \u001b[0;36mTracingCompiler._get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns a concrete function which cleans up its graph function.\"\"\"\u001b[39;00m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m--> 171\u001b[0m   concrete_function, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_define_concrete_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m concrete_function\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/missing/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:166\u001b[0m, in \u001b[0;36mTracingCompiler._maybe_define_concrete_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m   args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_signature\n\u001b[1;32m    164\u001b[0m   kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 166\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/missing/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:396\u001b[0m, in \u001b[0;36mTracingCompiler._maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    393\u001b[0m   args \u001b[38;5;241m=\u001b[39m placeholder_bound_args\u001b[38;5;241m.\u001b[39margs\n\u001b[1;32m    394\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m placeholder_bound_args\u001b[38;5;241m.\u001b[39mkwargs\n\u001b[0;32m--> 396\u001b[0m concrete_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_concrete_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    397\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;66;03m# TODO(b/263520817): Remove access to private attribute.\u001b[39;00m\n\u001b[1;32m    400\u001b[0m graph_capture_container \u001b[38;5;241m=\u001b[39m concrete_function\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39m_function_captures  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/missing/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:300\u001b[0m, in \u001b[0;36mTracingCompiler._create_concrete_function\u001b[0;34m(self, args, kwargs, func_graph)\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    297\u001b[0m   arg_names \u001b[38;5;241m=\u001b[39m base_arg_names\n\u001b[1;32m    299\u001b[0m concrete_function \u001b[38;5;241m=\u001b[39m monomorphic_function\u001b[38;5;241m.\u001b[39mConcreteFunction(\n\u001b[0;32m--> 300\u001b[0m     \u001b[43mfunc_graph_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc_graph_from_py_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_python_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    304\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    306\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[43m        \u001b[49m\u001b[43marg_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marg_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapture_by_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_capture_by_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcreate_placeholders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m,\n\u001b[1;32m    312\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_attributes,\n\u001b[1;32m    313\u001b[0m     spec\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_spec,\n\u001b[1;32m    314\u001b[0m     \u001b[38;5;66;03m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[1;32m    315\u001b[0m     \u001b[38;5;66;03m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[1;32m    316\u001b[0m     \u001b[38;5;66;03m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;66;03m# ConcreteFunction.\u001b[39;00m\n\u001b[1;32m    318\u001b[0m     shared_func_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m concrete_function\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/missing/lib/python3.10/site-packages/tensorflow/python/framework/func_graph.py:1214\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1211\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1212\u001b[0m   _, original_func \u001b[38;5;241m=\u001b[39m tf_decorator\u001b[38;5;241m.\u001b[39munwrap(python_func)\n\u001b[0;32m-> 1214\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mpython_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1216\u001b[0m \u001b[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[1;32m   1217\u001b[0m \u001b[38;5;66;03m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[1;32m   1218\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m variable_utils\u001b[38;5;241m.\u001b[39mconvert_variables_to_tensors(func_outputs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/missing/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:667\u001b[0m, in \u001b[0;36mFunction._compiler_with_scope.<locals>.wrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    663\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m default_graph\u001b[38;5;241m.\u001b[39m_variable_creator_scope(scope, priority\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m):  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    664\u001b[0m   \u001b[38;5;66;03m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[39;00m\n\u001b[1;32m    665\u001b[0m   \u001b[38;5;66;03m# the function a weak reference to itself to avoid a reference cycle.\u001b[39;00m\n\u001b[1;32m    666\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(compile_with_xla):\n\u001b[0;32m--> 667\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mweak_wrapped_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__wrapped__\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    668\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/missing/lib/python3.10/site-packages/tensorflow/python/framework/func_graph.py:1189\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;66;03m# TODO(mdan): Push this block higher in tf.function's call stack.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1189\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mautograph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1190\u001b[0m \u001b[43m      \u001b[49m\u001b[43moriginal_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1192\u001b[0m \u001b[43m      \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1193\u001b[0m \u001b[43m      \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautograph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mConversionOptions\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1194\u001b[0m \u001b[43m          \u001b[49m\u001b[43mrecursive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[43m          \u001b[49m\u001b[43moptional_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautograph_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1196\u001b[0m \u001b[43m          \u001b[49m\u001b[43muser_requested\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1197\u001b[0m \u001b[43m      \u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1198\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m   1199\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/missing/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:439\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    438\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 439\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mconverted_f\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43meffective_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    440\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    441\u001b[0m     result \u001b[38;5;241m=\u001b[39m converted_f(\u001b[38;5;241m*\u001b[39meffective_args)\n",
      "File \u001b[0;32m/var/folders/ql/g2lrtrss1ns2qlwbvzmvtgzm0000gn/T/__autograph_generated_filekcu9k3m9.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep_function\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/missing/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:377\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    374\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m options\u001b[38;5;241m.\u001b[39muser_requested \u001b[38;5;129;01mand\u001b[39;00m conversion\u001b[38;5;241m.\u001b[39mis_allowlisted(f):\n\u001b[0;32m--> 377\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_call_unconverted\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;66;03m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[39;00m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;66;03m# call conversion from generated code while in nonrecursive mode. In that\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;66;03m# case we evidently don't want to recurse, but we still have to convert\u001b[39;00m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;66;03m# things like builtins.\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m options\u001b[38;5;241m.\u001b[39minternal_convert_user_code:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/missing/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:459\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    458\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 459\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/missing/lib/python3.10/site-packages/keras/engine/training.py:1268\u001b[0m, in \u001b[0;36mModel.make_train_function.<locals>.step_function\u001b[0;34m(model, iterator)\u001b[0m\n\u001b[1;32m   1264\u001b[0m     run_step \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mfunction(\n\u001b[1;32m   1265\u001b[0m         run_step, jit_compile\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, reduce_retracing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1266\u001b[0m     )\n\u001b[1;32m   1267\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(iterator)\n\u001b[0;32m-> 1268\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribute_strategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1269\u001b[0m outputs \u001b[38;5;241m=\u001b[39m reduce_per_replica(\n\u001b[1;32m   1270\u001b[0m     outputs,\n\u001b[1;32m   1271\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_strategy,\n\u001b[1;32m   1272\u001b[0m     reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_reduction_method,\n\u001b[1;32m   1273\u001b[0m )\n\u001b[1;32m   1274\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/missing/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py:1316\u001b[0m, in \u001b[0;36mStrategyBase.run\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1311\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscope():\n\u001b[1;32m   1312\u001b[0m   \u001b[38;5;66;03m# tf.distribute supports Eager functions, so AutoGraph should not be\u001b[39;00m\n\u001b[1;32m   1313\u001b[0m   \u001b[38;5;66;03m# applied when the caller is also in Eager mode.\u001b[39;00m\n\u001b[1;32m   1314\u001b[0m   fn \u001b[38;5;241m=\u001b[39m autograph\u001b[38;5;241m.\u001b[39mtf_convert(\n\u001b[1;32m   1315\u001b[0m       fn, autograph_ctx\u001b[38;5;241m.\u001b[39mcontrol_status_ctx(), convert_by_default\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m-> 1316\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_extended\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_for_each_replica\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/missing/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py:2895\u001b[0m, in \u001b[0;36mStrategyExtendedV1.call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   2893\u001b[0m   kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m   2894\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_container_strategy()\u001b[38;5;241m.\u001b[39mscope():\n\u001b[0;32m-> 2895\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_for_each_replica\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/missing/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py:3696\u001b[0m, in \u001b[0;36m_DefaultDistributionExtended._call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   3694\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call_for_each_replica\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn, args, kwargs):\n\u001b[1;32m   3695\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ReplicaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_container_strategy(), replica_id_in_sync_group\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m-> 3696\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/missing/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:689\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    688\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m conversion_ctx:\n\u001b[0;32m--> 689\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    691\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/missing/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:377\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    374\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m options\u001b[38;5;241m.\u001b[39muser_requested \u001b[38;5;129;01mand\u001b[39;00m conversion\u001b[38;5;241m.\u001b[39mis_allowlisted(f):\n\u001b[0;32m--> 377\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_call_unconverted\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;66;03m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[39;00m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;66;03m# call conversion from generated code while in nonrecursive mode. In that\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;66;03m# case we evidently don't want to recurse, but we still have to convert\u001b[39;00m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;66;03m# things like builtins.\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m options\u001b[38;5;241m.\u001b[39minternal_convert_user_code:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/missing/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:458\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    455\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m\u001b[38;5;241m.\u001b[39mcall(args, kwargs)\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 458\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/missing/lib/python3.10/site-packages/keras/engine/training.py:1249\u001b[0m, in \u001b[0;36mModel.make_train_function.<locals>.step_function.<locals>.run_step\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m   1248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_step\u001b[39m(data):\n\u001b[0;32m-> 1249\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1250\u001b[0m     \u001b[38;5;66;03m# Ensure counter is updated only if `train_step` succeeds.\u001b[39;00m\n\u001b[1;32m   1251\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mcontrol_dependencies(_minimum_control_deps(outputs)):\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/missing/lib/python3.10/site-packages/keras/engine/training.py:1054\u001b[0m, in \u001b[0;36mModel.train_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_target_and_loss(y, loss)\n\u001b[1;32m   1053\u001b[0m \u001b[38;5;66;03m# Run backwards pass.\u001b[39;00m\n\u001b[0;32m-> 1054\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mminimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainable_variables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1055\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_metrics(x, y, y_pred, sample_weight)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/missing/lib/python3.10/site-packages/keras/optimizers/legacy/optimizer_v2.py:585\u001b[0m, in \u001b[0;36mOptimizerV2.minimize\u001b[0;34m(self, loss, var_list, grad_loss, name, tape)\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mminimize\u001b[39m(\u001b[38;5;28mself\u001b[39m, loss, var_list, grad_loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, tape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    555\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Minimize `loss` by updating `var_list`.\u001b[39;00m\n\u001b[1;32m    556\u001b[0m \n\u001b[1;32m    557\u001b[0m \u001b[38;5;124;03m    This method simply computes gradient using `tf.GradientTape` and calls\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    583\u001b[0m \n\u001b[1;32m    584\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 585\u001b[0m     grads_and_vars \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compute_gradients\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    586\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvar_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvar_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_loss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtape\u001b[49m\n\u001b[1;32m    587\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    588\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_gradients(grads_and_vars, name\u001b[38;5;241m=\u001b[39mname)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/missing/lib/python3.10/site-packages/keras/optimizers/legacy/optimizer_v2.py:643\u001b[0m, in \u001b[0;36mOptimizerV2._compute_gradients\u001b[0;34m(self, loss, var_list, grad_loss, tape)\u001b[0m\n\u001b[1;32m    641\u001b[0m var_list \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mflatten(var_list)\n\u001b[1;32m    642\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mname_scope(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/gradients\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 643\u001b[0m     grads_and_vars \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_gradients\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    644\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvar_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_loss\u001b[49m\n\u001b[1;32m    645\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    647\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assert_valid_dtypes(\n\u001b[1;32m    648\u001b[0m     [\n\u001b[1;32m    649\u001b[0m         v\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    652\u001b[0m     ]\n\u001b[1;32m    653\u001b[0m )\n\u001b[1;32m    655\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m grads_and_vars\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/missing/lib/python3.10/site-packages/keras/optimizers/legacy/optimizer_v2.py:519\u001b[0m, in \u001b[0;36mOptimizerV2._get_gradients\u001b[0;34m(self, tape, loss, var_list, grad_loss)\u001b[0m\n\u001b[1;32m    517\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_gradients\u001b[39m(\u001b[38;5;28mself\u001b[39m, tape, loss, var_list, grad_loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    518\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Called in `minimize` to compute gradients from loss.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 519\u001b[0m     grads \u001b[38;5;241m=\u001b[39m \u001b[43mtape\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgradient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvar_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_loss\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(grads, var_list))\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/missing/lib/python3.10/site-packages/tensorflow/python/eager/backprop.py:1063\u001b[0m, in \u001b[0;36mGradientTape.gradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1057\u001b[0m   output_gradients \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1058\u001b[0m       composite_tensor_gradient\u001b[38;5;241m.\u001b[39mget_flat_tensors_for_gradients(\n\u001b[1;32m   1059\u001b[0m           output_gradients))\n\u001b[1;32m   1060\u001b[0m   output_gradients \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mconvert_to_tensor(x)\n\u001b[1;32m   1061\u001b[0m                       \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m output_gradients]\n\u001b[0;32m-> 1063\u001b[0m flat_grad \u001b[38;5;241m=\u001b[39m \u001b[43mimperative_grad\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimperative_grad\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1064\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1065\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_targets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1066\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_sources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1067\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_gradients\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_gradients\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1068\u001b[0m \u001b[43m    \u001b[49m\u001b[43msources_raw\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mflat_sources_raw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1069\u001b[0m \u001b[43m    \u001b[49m\u001b[43munconnected_gradients\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munconnected_gradients\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1071\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_persistent:\n\u001b[1;32m   1072\u001b[0m   \u001b[38;5;66;03m# Keep track of watched variables before setting tape to None\u001b[39;00m\n\u001b[1;32m   1073\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_watched_variables \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tape\u001b[38;5;241m.\u001b[39mwatched_variables()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/missing/lib/python3.10/site-packages/tensorflow/python/eager/imperative_grad.py:67\u001b[0m, in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[1;32m     64\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     65\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown value for unconnected_gradients: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m unconnected_gradients)\n\u001b[0;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_TapeGradient\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtape\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m     69\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m    \u001b[49m\u001b[43msources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_gradients\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m    \u001b[49m\u001b[43msources_raw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_str\u001b[49m\u001b[43m(\u001b[49m\u001b[43munconnected_gradients\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/missing/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:634\u001b[0m, in \u001b[0;36m_DelayedRewriteGradientFunctions._backward.<locals>._backward_function\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_backward_function\u001b[39m(\u001b[38;5;241m*\u001b[39margs):\n\u001b[1;32m    633\u001b[0m   call_op \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mop\n\u001b[0;32m--> 634\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_rewrite_forward_and_call_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcall_op\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/missing/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:550\u001b[0m, in \u001b[0;36m_DelayedRewriteGradientFunctions._rewrite_forward_and_call_backward\u001b[0;34m(self, op, *doutputs)\u001b[0m\n\u001b[1;32m    548\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_rewrite_forward_and_call_backward\u001b[39m(\u001b[38;5;28mself\u001b[39m, op, \u001b[38;5;241m*\u001b[39mdoutputs):\n\u001b[1;32m    549\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Add outputs to the forward call and feed them to the grad function.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 550\u001b[0m   forward_function, backwards_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdoutputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    551\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m backwards_function\u001b[38;5;241m.\u001b[39moutputs:\n\u001b[1;32m    552\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m backwards_function\u001b[38;5;241m.\u001b[39mstructured_outputs\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/missing/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:483\u001b[0m, in \u001b[0;36m_DelayedRewriteGradientFunctions.forward_backward\u001b[0;34m(self, num_doutputs)\u001b[0m\n\u001b[1;32m    481\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m forward_backward \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    482\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m forward_backward\n\u001b[0;32m--> 483\u001b[0m forward, backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_construct_forward_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_doutputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cached_function_pairs[num_doutputs] \u001b[38;5;241m=\u001b[39m (forward, backward)\n\u001b[1;32m    485\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m forward, backward\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/missing/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:526\u001b[0m, in \u001b[0;36m_DelayedRewriteGradientFunctions._construct_forward_backward\u001b[0;34m(self, num_doutputs)\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_func_graph\u001b[38;5;241m.\u001b[39mas_default():\n\u001b[1;32m    524\u001b[0m   backwards_graph \u001b[38;5;241m=\u001b[39m func_graph_module\u001b[38;5;241m.\u001b[39mFuncGraph(\n\u001b[1;32m    525\u001b[0m       _backward_name(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_func_graph\u001b[38;5;241m.\u001b[39mname))\n\u001b[0;32m--> 526\u001b[0m   \u001b[43mfunc_graph_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc_graph_from_py_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbackwards_graph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    528\u001b[0m \u001b[43m      \u001b[49m\u001b[43mpython_func\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_backprop_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    529\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    530\u001b[0m \u001b[43m      \u001b[49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[43m      \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbackwards_graph\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    532\u001b[0m   backwards_graph_captures \u001b[38;5;241m=\u001b[39m backwards_graph\u001b[38;5;241m.\u001b[39mexternal_captures\n\u001b[1;32m    533\u001b[0m   captures_from_forward \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    534\u001b[0m       c \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m backwards_graph_captures \u001b[38;5;28;01mif\u001b[39;00m\n\u001b[1;32m    535\u001b[0m       \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(c, ops\u001b[38;5;241m.\u001b[39mEagerTensor) \u001b[38;5;129;01mand\u001b[39;00m c\u001b[38;5;241m.\u001b[39mgraph \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_func_graph]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/missing/lib/python3.10/site-packages/tensorflow/python/framework/func_graph.py:1214\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1211\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1212\u001b[0m   _, original_func \u001b[38;5;241m=\u001b[39m tf_decorator\u001b[38;5;241m.\u001b[39munwrap(python_func)\n\u001b[0;32m-> 1214\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mpython_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1216\u001b[0m \u001b[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[1;32m   1217\u001b[0m \u001b[38;5;66;03m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[1;32m   1218\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m variable_utils\u001b[38;5;241m.\u001b[39mconvert_variables_to_tensors(func_outputs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/missing/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:517\u001b[0m, in \u001b[0;36m_DelayedRewriteGradientFunctions._construct_forward_backward.<locals>._backprop_function\u001b[0;34m(*grad_ys)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_backprop_function\u001b[39m(\u001b[38;5;241m*\u001b[39mgrad_ys):\n\u001b[1;32m    516\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 517\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgradients_util\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_GradientsHelper\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    518\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrainable_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    519\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func_graph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    520\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_ys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_ys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    521\u001b[0m \u001b[43m        \u001b[49m\u001b[43msrc_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func_graph\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/missing/lib/python3.10/site-packages/tensorflow/python/ops/gradients_util.py:695\u001b[0m, in \u001b[0;36m_GradientsHelper\u001b[0;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients, src_graph)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m src_graph\u001b[38;5;241m.\u001b[39m_original_op(op):\n\u001b[1;32m    691\u001b[0m   \u001b[38;5;66;03m# pylint: enable=protected-access\u001b[39;00m\n\u001b[1;32m    692\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m grad_fn:\n\u001b[1;32m    693\u001b[0m     \u001b[38;5;66;03m# If grad_fn was found, do not use SymbolicGradient even for\u001b[39;00m\n\u001b[1;32m    694\u001b[0m     \u001b[38;5;66;03m# functions.\u001b[39;00m\n\u001b[0;32m--> 695\u001b[0m     in_grads \u001b[38;5;241m=\u001b[39m \u001b[43m_MaybeCompile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad_scope\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    696\u001b[0m \u001b[43m                             \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mout_grads\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    697\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    698\u001b[0m     \u001b[38;5;66;03m# For function call ops, we add a 'SymbolicGradient'\u001b[39;00m\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;66;03m# node to the graph to compute gradients.\u001b[39;00m\n\u001b[1;32m    700\u001b[0m     in_grads \u001b[38;5;241m=\u001b[39m _MaybeCompile(grad_scope, op, func_call,\n\u001b[1;32m    701\u001b[0m                              \u001b[38;5;28;01mlambda\u001b[39;00m: _SymGrad(op, out_grads))\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/missing/lib/python3.10/site-packages/tensorflow/python/ops/gradients_util.py:329\u001b[0m, in \u001b[0;36m_MaybeCompile\u001b[0;34m(scope, op, func, grad_fn)\u001b[0m\n\u001b[1;32m    326\u001b[0m     xla_compile \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    328\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m xla_compile:\n\u001b[0;32m--> 329\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgrad_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Exit early\u001b[39;00m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;66;03m# If the gradients are supposed to be compiled separately, we give them a\u001b[39;00m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;66;03m# _XlaScope name that is based on the name_scope of the gradients.  Otherwise\u001b[39;00m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;66;03m# they just inherit the existing _XlaScope name, which lets them be merged\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;66;03m# together with the non-gradient computation.\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m xla_separate_compiled_gradients:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/missing/lib/python3.10/site-packages/tensorflow/python/ops/gradients_util.py:696\u001b[0m, in \u001b[0;36m_GradientsHelper.<locals>.<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m src_graph\u001b[38;5;241m.\u001b[39m_original_op(op):\n\u001b[1;32m    691\u001b[0m   \u001b[38;5;66;03m# pylint: enable=protected-access\u001b[39;00m\n\u001b[1;32m    692\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m grad_fn:\n\u001b[1;32m    693\u001b[0m     \u001b[38;5;66;03m# If grad_fn was found, do not use SymbolicGradient even for\u001b[39;00m\n\u001b[1;32m    694\u001b[0m     \u001b[38;5;66;03m# functions.\u001b[39;00m\n\u001b[1;32m    695\u001b[0m     in_grads \u001b[38;5;241m=\u001b[39m _MaybeCompile(grad_scope, op, func_call,\n\u001b[0;32m--> 696\u001b[0m                              \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[43mgrad_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mout_grads\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    697\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    698\u001b[0m     \u001b[38;5;66;03m# For function call ops, we add a 'SymbolicGradient'\u001b[39;00m\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;66;03m# node to the graph to compute gradients.\u001b[39;00m\n\u001b[1;32m    700\u001b[0m     in_grads \u001b[38;5;241m=\u001b[39m _MaybeCompile(grad_scope, op, func_call,\n\u001b[1;32m    701\u001b[0m                              \u001b[38;5;28;01mlambda\u001b[39;00m: _SymGrad(op, out_grads))\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/missing/lib/python3.10/site-packages/tensorflow/python/ops/while_v2.py:394\u001b[0m, in \u001b[0;36m_WhileGrad\u001b[0;34m(op, *grads)\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[38;5;66;03m# We compute the gradient for the sub-graph between trainable ys and xs\u001b[39;00m\n\u001b[1;32m    389\u001b[0m \u001b[38;5;66;03m# with non-None incoming gradients. We later pad the None's to the list of\u001b[39;00m\n\u001b[1;32m    390\u001b[0m \u001b[38;5;66;03m# outputs.\u001b[39;00m\n\u001b[1;32m    391\u001b[0m ys, xs, non_none_grads \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39m[(y, x, grad) \u001b[38;5;28;01mfor\u001b[39;00m (y, x, grad) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\n\u001b[1;32m    392\u001b[0m     body_graph\u001b[38;5;241m.\u001b[39moutputs, body_graph\u001b[38;5;241m.\u001b[39minputs, grads) \u001b[38;5;28;01mif\u001b[39;00m grad \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m])\n\u001b[0;32m--> 394\u001b[0m body_grad_graph, args \u001b[38;5;241m=\u001b[39m \u001b[43m_create_grad_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    395\u001b[0m \u001b[43m    \u001b[49m\u001b[43mys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_none_grads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcond_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    396\u001b[0m \u001b[43m    \u001b[49m\u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique_grad_fn_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbody_graph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaximum_iterations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    397\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstateful_parallelism\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m body_grad_graph\u001b[38;5;241m.\u001b[39mwhile_op_needs_rewrite:\n\u001b[1;32m    400\u001b[0m   \u001b[38;5;66;03m# Modify 'op' to output the intermediate accumulators needed by the grad\u001b[39;00m\n\u001b[1;32m    401\u001b[0m   \u001b[38;5;66;03m# function.\u001b[39;00m\n\u001b[1;32m    402\u001b[0m   \u001b[38;5;66;03m# NOTE(skyewm): if there are any active sessions, this modification to `op`\u001b[39;00m\n\u001b[1;32m    403\u001b[0m   \u001b[38;5;66;03m# may make them unrunnable!\u001b[39;00m\n\u001b[1;32m    405\u001b[0m   cond_graph\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_rewritten\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/missing/lib/python3.10/site-packages/tensorflow/python/ops/while_v2.py:696\u001b[0m, in \u001b[0;36m_create_grad_func\u001b[0;34m(ys, xs, grads, cond_graph, body_graph, name, while_op, maximum_iterations, stateful_parallelism)\u001b[0m\n\u001b[1;32m    693\u001b[0m args \u001b[38;5;241m=\u001b[39m [counter, maximum_iterations, total_iters] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(grads)\n\u001b[1;32m    694\u001b[0m \u001b[38;5;66;03m# Note: The returned function does not have `args` in the list of\u001b[39;00m\n\u001b[1;32m    695\u001b[0m \u001b[38;5;66;03m# `external_captures`.\u001b[39;00m\n\u001b[0;32m--> 696\u001b[0m grad_func_graph \u001b[38;5;241m=\u001b[39m \u001b[43mfunc_graph_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc_graph_from_py_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    698\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m_grad_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody_graph\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    699\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    700\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_WhileBodyGradFuncGraph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcond_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    701\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43mmaximum_iterations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhile_op\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43mbody_graph_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody_graph_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    703\u001b[0m \u001b[43m    \u001b[49m\u001b[43macd_record_initial_resource_uses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstateful_parallelism\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Update the list of outputs with tensors corresponding to the captured\u001b[39;00m\n\u001b[1;32m    706\u001b[0m \u001b[38;5;66;03m# tensors. We capture 3 types of tensors when building the grad fn:\u001b[39;00m\n\u001b[1;32m    707\u001b[0m \u001b[38;5;66;03m# 1. Accumulators for forward graph intermediates which are not loop\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    710\u001b[0m \u001b[38;5;66;03m# 2. Resources, which are output as is.\u001b[39;00m\n\u001b[1;32m    711\u001b[0m \u001b[38;5;66;03m# 3. Forward graph loop invariants, which are output as is.\u001b[39;00m\n\u001b[1;32m    712\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m external_capture, internal_capture \u001b[38;5;129;01min\u001b[39;00m grad_func_graph\u001b[38;5;241m.\u001b[39mcaptures:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/missing/lib/python3.10/site-packages/tensorflow/python/framework/func_graph.py:1214\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1211\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1212\u001b[0m   _, original_func \u001b[38;5;241m=\u001b[39m tf_decorator\u001b[38;5;241m.\u001b[39munwrap(python_func)\n\u001b[0;32m-> 1214\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mpython_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1216\u001b[0m \u001b[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[1;32m   1217\u001b[0m \u001b[38;5;66;03m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[1;32m   1218\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m variable_utils\u001b[38;5;241m.\u001b[39mconvert_variables_to_tensors(func_outputs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/missing/lib/python3.10/site-packages/tensorflow/python/ops/while_v2.py:698\u001b[0m, in \u001b[0;36m_create_grad_func.<locals>.<lambda>\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    693\u001b[0m args \u001b[38;5;241m=\u001b[39m [counter, maximum_iterations, total_iters] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(grads)\n\u001b[1;32m    694\u001b[0m \u001b[38;5;66;03m# Note: The returned function does not have `args` in the list of\u001b[39;00m\n\u001b[1;32m    695\u001b[0m \u001b[38;5;66;03m# `external_captures`.\u001b[39;00m\n\u001b[1;32m    696\u001b[0m grad_func_graph \u001b[38;5;241m=\u001b[39m func_graph_module\u001b[38;5;241m.\u001b[39mfunc_graph_from_py_func(\n\u001b[1;32m    697\u001b[0m     name,\n\u001b[0;32m--> 698\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;241m*\u001b[39margs: \u001b[43m_grad_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody_graph\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    699\u001b[0m     args, {},\n\u001b[1;32m    700\u001b[0m     func_graph\u001b[38;5;241m=\u001b[39m_WhileBodyGradFuncGraph(name, cond_graph, body_graph,\n\u001b[1;32m    701\u001b[0m                                        maximum_iterations, while_op,\n\u001b[1;32m    702\u001b[0m                                        body_graph_inputs, body_graph_outputs),\n\u001b[1;32m    703\u001b[0m     acd_record_initial_resource_uses\u001b[38;5;241m=\u001b[39mstateful_parallelism)\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Update the list of outputs with tensors corresponding to the captured\u001b[39;00m\n\u001b[1;32m    706\u001b[0m \u001b[38;5;66;03m# tensors. We capture 3 types of tensors when building the grad fn:\u001b[39;00m\n\u001b[1;32m    707\u001b[0m \u001b[38;5;66;03m# 1. Accumulators for forward graph intermediates which are not loop\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    710\u001b[0m \u001b[38;5;66;03m# 2. Resources, which are output as is.\u001b[39;00m\n\u001b[1;32m    711\u001b[0m \u001b[38;5;66;03m# 3. Forward graph loop invariants, which are output as is.\u001b[39;00m\n\u001b[1;32m    712\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m external_capture, internal_capture \u001b[38;5;129;01min\u001b[39;00m grad_func_graph\u001b[38;5;241m.\u001b[39mcaptures:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/missing/lib/python3.10/site-packages/tensorflow/python/ops/while_v2.py:754\u001b[0m, in \u001b[0;36m_grad_fn\u001b[0;34m(ys, xs, args, func_graph)\u001b[0m\n\u001b[1;32m    747\u001b[0m grad_ys \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m3\u001b[39m:]\n\u001b[1;32m    749\u001b[0m \u001b[38;5;66;03m# Build the gradient graph. Note that this builds the gradient computation of\u001b[39;00m\n\u001b[1;32m    750\u001b[0m \u001b[38;5;66;03m# func_graph in the current graph, which requires capturing tensors from\u001b[39;00m\n\u001b[1;32m    751\u001b[0m \u001b[38;5;66;03m# func_graph. The captured func_graph tensors are resolved to external tensors\u001b[39;00m\n\u001b[1;32m    752\u001b[0m \u001b[38;5;66;03m# after the forward While op has been rewritten in _resolve_grad_captures.\u001b[39;00m\n\u001b[1;32m    753\u001b[0m \u001b[38;5;66;03m# TODO(srbs): Mark GradientsHelper as public?\u001b[39;00m\n\u001b[0;32m--> 754\u001b[0m grad_outs \u001b[38;5;241m=\u001b[39m \u001b[43mgradients_util\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_GradientsHelper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    755\u001b[0m \u001b[43m    \u001b[49m\u001b[43mys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_ys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_ys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    756\u001b[0m \u001b[43m    \u001b[49m\u001b[43munconnected_gradients\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mzero\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    758\u001b[0m \u001b[38;5;66;03m# TODO(b/118712257): Handle the case when grad_outs has None's e.g. when there\u001b[39;00m\n\u001b[1;32m    759\u001b[0m \u001b[38;5;66;03m# is a tf.StopGradient in the loop body.\u001b[39;00m\n\u001b[1;32m    760\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mall\u001b[39m(g \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m g \u001b[38;5;129;01min\u001b[39;00m grad_outs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/missing/lib/python3.10/site-packages/tensorflow/python/ops/gradients_util.py:695\u001b[0m, in \u001b[0;36m_GradientsHelper\u001b[0;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients, src_graph)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m src_graph\u001b[38;5;241m.\u001b[39m_original_op(op):\n\u001b[1;32m    691\u001b[0m   \u001b[38;5;66;03m# pylint: enable=protected-access\u001b[39;00m\n\u001b[1;32m    692\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m grad_fn:\n\u001b[1;32m    693\u001b[0m     \u001b[38;5;66;03m# If grad_fn was found, do not use SymbolicGradient even for\u001b[39;00m\n\u001b[1;32m    694\u001b[0m     \u001b[38;5;66;03m# functions.\u001b[39;00m\n\u001b[0;32m--> 695\u001b[0m     in_grads \u001b[38;5;241m=\u001b[39m \u001b[43m_MaybeCompile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad_scope\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    696\u001b[0m \u001b[43m                             \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mout_grads\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    697\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    698\u001b[0m     \u001b[38;5;66;03m# For function call ops, we add a 'SymbolicGradient'\u001b[39;00m\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;66;03m# node to the graph to compute gradients.\u001b[39;00m\n\u001b[1;32m    700\u001b[0m     in_grads \u001b[38;5;241m=\u001b[39m _MaybeCompile(grad_scope, op, func_call,\n\u001b[1;32m    701\u001b[0m                              \u001b[38;5;28;01mlambda\u001b[39;00m: _SymGrad(op, out_grads))\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/missing/lib/python3.10/site-packages/tensorflow/python/ops/gradients_util.py:329\u001b[0m, in \u001b[0;36m_MaybeCompile\u001b[0;34m(scope, op, func, grad_fn)\u001b[0m\n\u001b[1;32m    326\u001b[0m     xla_compile \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    328\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m xla_compile:\n\u001b[0;32m--> 329\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgrad_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Exit early\u001b[39;00m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;66;03m# If the gradients are supposed to be compiled separately, we give them a\u001b[39;00m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;66;03m# _XlaScope name that is based on the name_scope of the gradients.  Otherwise\u001b[39;00m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;66;03m# they just inherit the existing _XlaScope name, which lets them be merged\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;66;03m# together with the non-gradient computation.\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m xla_separate_compiled_gradients:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/missing/lib/python3.10/site-packages/tensorflow/python/ops/gradients_util.py:696\u001b[0m, in \u001b[0;36m_GradientsHelper.<locals>.<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m src_graph\u001b[38;5;241m.\u001b[39m_original_op(op):\n\u001b[1;32m    691\u001b[0m   \u001b[38;5;66;03m# pylint: enable=protected-access\u001b[39;00m\n\u001b[1;32m    692\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m grad_fn:\n\u001b[1;32m    693\u001b[0m     \u001b[38;5;66;03m# If grad_fn was found, do not use SymbolicGradient even for\u001b[39;00m\n\u001b[1;32m    694\u001b[0m     \u001b[38;5;66;03m# functions.\u001b[39;00m\n\u001b[1;32m    695\u001b[0m     in_grads \u001b[38;5;241m=\u001b[39m _MaybeCompile(grad_scope, op, func_call,\n\u001b[0;32m--> 696\u001b[0m                              \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[43mgrad_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mout_grads\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    697\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    698\u001b[0m     \u001b[38;5;66;03m# For function call ops, we add a 'SymbolicGradient'\u001b[39;00m\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;66;03m# node to the graph to compute gradients.\u001b[39;00m\n\u001b[1;32m    700\u001b[0m     in_grads \u001b[38;5;241m=\u001b[39m _MaybeCompile(grad_scope, op, func_call,\n\u001b[1;32m    701\u001b[0m                              \u001b[38;5;28;01mlambda\u001b[39;00m: _SymGrad(op, out_grads))\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/missing/lib/python3.10/site-packages/tensorflow/python/ops/math_grad.py:1378\u001b[0m, in \u001b[0;36m_MulGrad\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m   1375\u001b[0m   gx \u001b[38;5;241m=\u001b[39m gen_math_ops\u001b[38;5;241m.\u001b[39mmul(grad, y)\n\u001b[1;32m   1376\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1377\u001b[0m   gx \u001b[38;5;241m=\u001b[39m array_ops\u001b[38;5;241m.\u001b[39mreshape(\n\u001b[0;32m-> 1378\u001b[0m       math_ops\u001b[38;5;241m.\u001b[39mreduce_sum(\u001b[43mgen_math_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m, rx), sx)\n\u001b[1;32m   1379\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m skip_input_indices \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01min\u001b[39;00m skip_input_indices:\n\u001b[1;32m   1380\u001b[0m   gy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/missing/lib/python3.10/site-packages/tensorflow/python/ops/gen_math_ops.py:6589\u001b[0m, in \u001b[0;36mmul\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   6587\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# Add nodes to the TensorFlow graph.\u001b[39;00m\n\u001b[1;32m   6588\u001b[0m \u001b[38;5;66;03m# Add nodes to the TensorFlow graph.\u001b[39;00m\n\u001b[0;32m-> 6589\u001b[0m _, _, _op, _outputs \u001b[38;5;241m=\u001b[39m \u001b[43m_op_def_library\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply_op_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   6590\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMul\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6591\u001b[0m _result \u001b[38;5;241m=\u001b[39m _outputs[:]\n\u001b[1;32m   6592\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _execute\u001b[38;5;241m.\u001b[39mmust_record_gradient():\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/missing/lib/python3.10/site-packages/tensorflow/python/framework/op_def_library.py:795\u001b[0m, in \u001b[0;36m_apply_op_helper\u001b[0;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    790\u001b[0m must_colocate_inputs \u001b[38;5;241m=\u001b[39m [val \u001b[38;5;28;01mfor\u001b[39;00m arg, val \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(op_def\u001b[38;5;241m.\u001b[39minput_arg, inputs)\n\u001b[1;32m    791\u001b[0m                         \u001b[38;5;28;01mif\u001b[39;00m arg\u001b[38;5;241m.\u001b[39mis_ref]\n\u001b[1;32m    792\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _MaybeColocateWith(must_colocate_inputs):\n\u001b[1;32m    793\u001b[0m   \u001b[38;5;66;03m# Add Op to graph\u001b[39;00m\n\u001b[1;32m    794\u001b[0m   \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m--> 795\u001b[0m   op \u001b[38;5;241m=\u001b[39m \u001b[43mg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_op_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop_type_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtypes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscope\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattr_protos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_def\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mop_def\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[38;5;66;03m# `outputs` is returned as a separate return value so that the output\u001b[39;00m\n\u001b[1;32m    800\u001b[0m \u001b[38;5;66;03m# tensors can the `op` per se can be decoupled so that the\u001b[39;00m\n\u001b[1;32m    801\u001b[0m \u001b[38;5;66;03m# `op_callbacks` can function properly. See framework/op_callbacks.py\u001b[39;00m\n\u001b[1;32m    802\u001b[0m \u001b[38;5;66;03m# for more details.\u001b[39;00m\n\u001b[1;32m    803\u001b[0m outputs \u001b[38;5;241m=\u001b[39m op\u001b[38;5;241m.\u001b[39moutputs\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/missing/lib/python3.10/site-packages/tensorflow/python/ops/while_v2.py:1045\u001b[0m, in \u001b[0;36m_WhileBodyGradFuncGraph._create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (op_type \u001b[38;5;129;01min\u001b[39;00m optimized_reduction_ops \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m   1029\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m util\u001b[38;5;241m.\u001b[39moutput_all_intermediates() \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m   1030\u001b[0m     \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mgraph \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_graph \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28minput\u001b[39m \u001b[38;5;129;01min\u001b[39;00m inputs) \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1033\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m util\u001b[38;5;241m.\u001b[39mgraph_wrapped_for_higher_order_tape_gradients(\n\u001b[1;32m   1034\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_graph)):\n\u001b[1;32m   1035\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_move_op_to_forward_graph(\n\u001b[1;32m   1036\u001b[0m       op_type,\n\u001b[1;32m   1037\u001b[0m       inputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1042\u001b[0m       op_def\u001b[38;5;241m=\u001b[39mop_def,\n\u001b[1;32m   1043\u001b[0m       compute_device\u001b[38;5;241m=\u001b[39mcompute_device)\n\u001b[0;32m-> 1045\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_WhileBodyGradFuncGraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_op_internal\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1046\u001b[0m \u001b[43m    \u001b[49m\u001b[43mop_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1047\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1048\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtypes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtypes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1049\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1050\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1051\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1052\u001b[0m \u001b[43m    \u001b[49m\u001b[43mop_def\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mop_def\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1053\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompute_device\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompute_device\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/missing/lib/python3.10/site-packages/tensorflow/python/framework/func_graph.py:705\u001b[0m, in \u001b[0;36mFuncGraph._create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m    703\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m ctxt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(ctxt, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAddValue\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    704\u001b[0m     inp \u001b[38;5;241m=\u001b[39m ctxt\u001b[38;5;241m.\u001b[39mAddValue(inp)\n\u001b[0;32m--> 705\u001b[0m   inp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcapture\u001b[49m\u001b[43m(\u001b[49m\u001b[43minp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    706\u001b[0m   captured_inputs\u001b[38;5;241m.\u001b[39mappend(inp)\n\u001b[1;32m    707\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m_create_op_internal(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    708\u001b[0m     op_type, captured_inputs, dtypes, input_types, name, attrs, op_def,\n\u001b[1;32m    709\u001b[0m     compute_device)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/missing/lib/python3.10/site-packages/tensorflow/python/framework/func_graph.py:772\u001b[0m, in \u001b[0;36mFuncGraph.capture\u001b[0;34m(self, tensor, name, shape)\u001b[0m\n\u001b[1;32m    762\u001b[0m       \u001b[38;5;28;01mraise\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mInaccessibleTensorError(\n\u001b[1;32m    763\u001b[0m           \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtensor\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m is out of scope and cannot be used here. Use return \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    764\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues, explicit Python locals or TensorFlow collections to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    769\u001b[0m           \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe tensor \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtensor\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m cannot be accessed from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, because \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    770\u001b[0m           \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mit was defined in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtensor\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, which is out of scope.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    771\u001b[0m     inner_graph \u001b[38;5;241m=\u001b[39m inner_graph\u001b[38;5;241m.\u001b[39mouter_graph\n\u001b[0;32m--> 772\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_capture_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    773\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tensor\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/missing/lib/python3.10/site-packages/tensorflow/python/ops/while_v2.py:1217\u001b[0m, in \u001b[0;36m_WhileBodyGradFuncGraph._capture_helper\u001b[0;34m(self, tensor, name)\u001b[0m\n\u001b[1;32m   1213\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mextra_inputs\u001b[38;5;241m.\u001b[39mappend(tensor_list)\n\u001b[1;32m   1215\u001b[0m \u001b[38;5;66;03m# Push the intermediate tensor to the tensor list. This captures\u001b[39;00m\n\u001b[1;32m   1216\u001b[0m \u001b[38;5;66;03m# `tensor_list`.\u001b[39;00m\n\u001b[0;32m-> 1217\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_graph\u001b[38;5;241m.\u001b[39mas_default():\n\u001b[1;32m   1218\u001b[0m   accumulator \u001b[38;5;241m=\u001b[39m list_ops\u001b[38;5;241m.\u001b[39mtensor_list_push_back(tensor_list, tensor)\n\u001b[1;32m   1219\u001b[0m \u001b[38;5;66;03m# Add the modified tensor list to the list of outputs. This output will be\u001b[39;00m\n\u001b[1;32m   1220\u001b[0m \u001b[38;5;66;03m# all the accumulated values.\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/missing/lib/python3.10/contextlib.py:135\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt yield\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/missing/lib/python3.10/site-packages/tensorflow/python/framework/func_graph.py:509\u001b[0m, in \u001b[0;36mFuncGraph.as_default.<locals>.inner_cm\u001b[0;34m()\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[38;5;66;03m# We ignore device placements from any outer scopes while tracing the\u001b[39;00m\n\u001b[1;32m    496\u001b[0m \u001b[38;5;66;03m# function when possible, to avoid hard-coding them in the function\u001b[39;00m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;66;03m# graph. \"Default\" placements come from the PartitionedCallOp's placement,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[38;5;66;03m# 1. device stack is callable\u001b[39;00m\n\u001b[1;32m    504\u001b[0m \u001b[38;5;66;03m# 2. When using distribution strategy with legacy graph mode.\u001b[39;00m\n\u001b[1;32m    505\u001b[0m old_device_stack \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_device_function_stack\n\u001b[1;32m    506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly() \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    507\u001b[0m     (device_stack_has_callable(graph\u001b[38;5;241m.\u001b[39m_device_function_stack) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m    508\u001b[0m      (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_distribution_strategy_stack \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m--> 509\u001b[0m       \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecuting_eagerly_outside_functions\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m))):\n\u001b[1;32m    510\u001b[0m   \u001b[38;5;66;03m# Hard-code devices from device functions in the function body\u001b[39;00m\n\u001b[1;32m    511\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_device_function_stack \u001b[38;5;241m=\u001b[39m graph\u001b[38;5;241m.\u001b[39m_device_function_stack\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    513\u001b[0m old_creator_stack \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creator_stack\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/missing/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:6111\u001b[0m, in \u001b[0;36mexecuting_eagerly_outside_functions\u001b[0;34m()\u001b[0m\n\u001b[1;32m   6109\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   6110\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 6111\u001b[0m   outer_context, _ \u001b[38;5;241m=\u001b[39m \u001b[43m_get_outer_context_and_inner_device_stack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6112\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m outer_context():\n\u001b[1;32m   6113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/missing/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:5956\u001b[0m, in \u001b[0;36m_get_outer_context_and_inner_device_stack\u001b[0;34m()\u001b[0m\n\u001b[1;32m   5953\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   5954\u001b[0m   \u001b[38;5;66;03m# Find a context that is not building a function.\u001b[39;00m\n\u001b[1;32m   5955\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m stack_entry \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mreversed\u001b[39m(context\u001b[38;5;241m.\u001b[39mcontext()\u001b[38;5;241m.\u001b[39mcontext_switches\u001b[38;5;241m.\u001b[39mstack):\n\u001b[0;32m-> 5956\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m innermost_nonempty_device_stack:\n\u001b[1;32m   5957\u001b[0m       innermost_nonempty_device_stack \u001b[38;5;241m=\u001b[39m stack_entry\u001b[38;5;241m.\u001b[39mdevice_stack\n\u001b[1;32m   5958\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stack_entry\u001b[38;5;241m.\u001b[39mis_building_function:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/missing/lib/python3.10/site-packages/tensorflow/python/framework/traceable_stack.py:119\u001b[0m, in \u001b[0;36mTraceableStack.__len__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__len__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    118\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Return number of items on the stack, and used for truth-value testing.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 119\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stack\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "em.fit(val_data=dl2, filepath=\"./example.hdf5\", metric_curve=\"ROC\", epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-26 22:34:04.139239: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "em_no_miss = EmbeddingLSTMModel(dl_no_miss, True, 2)\n",
    "em_no_miss.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "63/63 [==============================] - 8s 44ms/step - loss: 0.6687 - auc: 0.5587 - val_loss: 0.6420 - val_auc: 0.5488\n",
      "Epoch 2/5\n",
      "63/63 [==============================] - 1s 18ms/step - loss: 0.5921 - auc: 0.4848 - val_loss: 0.5127 - val_auc: 0.5165\n",
      "Epoch 3/5\n",
      "63/63 [==============================] - 1s 18ms/step - loss: 0.4651 - auc: 0.5001 - val_loss: 0.4308 - val_auc: 0.4997\n",
      "Epoch 4/5\n",
      "63/63 [==============================] - 1s 17ms/step - loss: 0.4295 - auc: 0.4864 - val_loss: 0.4197 - val_auc: 0.5098\n",
      "Epoch 5/5\n",
      "63/63 [==============================] - 1s 18ms/step - loss: 0.4176 - auc: 0.5107 - val_loss: 0.4113 - val_auc: 0.5204\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff682b6dd50>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "em_no_miss.fit(val_data=dl_no_miss, filepath=\"./example.hdf5\", metric_curve=\"ROC\", epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([1, 2], dtype=int32)>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant([1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.9.1'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "missingdata",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
